{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Activation, Dense, Conv2D, MaxPooling2D, Conv3D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras import initializers\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset  and  Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "42000\n",
      "42000\n",
      "18000\n",
      "18000\n"
     ]
    }
   ],
   "source": [
    "data = h5py.File('SVHN_single_grey1.h5', 'r')\n",
    "print(len(data))\n",
    "xtrain = data[\"X_train\"][:]\n",
    "ytrain = data[\"y_train\"][:]\n",
    "\n",
    "#Test set\n",
    "xtest = data[\"X_test\"][:]\n",
    "ytest = data[\"y_test\"][:]\n",
    "\n",
    "# Validation Set\n",
    "xval = data[\"X_val\"][:]\n",
    "yval = data[\"y_val\"][:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of xtrain : {0} (42000, 32, 32)\n",
      "Shape of ytrain : {0} (42000,)\n",
      "Shape of xtest : {0} (18000, 32, 32)\n",
      "Shape of ytest : {0} (18000,)\n",
      "Shape of xval : {0} (60000, 32, 32)\n",
      "Shape of yval : {0} (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of xtrain : {0}\", xtrain.shape)\n",
    "print(\"Shape of ytrain : {0}\", ytrain.shape)\n",
    "print(\"Shape of xtest : {0}\", xtest.shape)\n",
    "print(\"Shape of ytest : {0}\", ytest.shape)\n",
    "print(\"Shape of xval : {0}\", xval.shape)\n",
    "print(\"Shape of yval : {0}\", yval.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode the class vector\n",
    "- convert class vectors (integers) to binary class matrix\n",
    "- convert y_train and y_test\n",
    "- number of classes: 10\n",
    "- we are doing this to use categorical_crossentropy as loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping X data: (n, 32, 32) => (n, 1024)\n",
    "x_train = xtrain.reshape(42000, 1024)\n",
    "x_test = xtest.reshape(18000, 1024)\n",
    "x_val = xval.reshape(60000, 1024)\n",
    "# converting y data into categorical (one-hot encoding)\n",
    "y_train = to_categorical(ytrain)\n",
    "y_test = to_categorical(ytest)\n",
    "y_val = to_categorical(yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024) (18000, 1024) (42000, 10) (18000, 10) (60000, 1024) (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Normalize features from 0-255 to 0-1\n",
    "print(x_train.max().round())\n",
    "print(x_train.min())\n",
    "def Normalize(x , xtest, xval):\n",
    "    X_train_normalize = x / 255.0\n",
    "    x_test_normalize = xtest / 255.0\n",
    "    x_val_normalize = xval/ 255.0\n",
    "    return X_train_normalize.round(), x_test_normalize.round(), x_val_normalize.round()\n",
    "\n",
    "\n",
    "X_train_normalize, x_test_normalize, x_val_normalize = Normalize(x_train, x_test, x_val)\n",
    "print(X_train_normalize.max().round())\n",
    "print(x_test_normalize.max().round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Observation\n",
    "1. Normalizing the dat so that value is with in range of 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data fetching and understand the train/val/test splits. (15 points) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  1\n"
     ]
    }
   ],
   "source": [
    "#1. We have already splitted the data in Training test and validation\n",
    "# seeing few samples of the output data\n",
    "index = [1,10,35,47,89,900,380, 1004,2567]\n",
    "for i in index :\n",
    "    plt.imshow(xtrain[i]) \n",
    "    plt.show()\n",
    "    print('Label: ', ytrain[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the below image: 2\n",
      "label for each of the below image: 6\n",
      "label for each of the below image: 7\n",
      "label for each of the below image: 4\n",
      "label for each of the below image: 4\n",
      "label for each of the below image: 0\n",
      "label for each of the below image: 3\n",
      "label for each of the below image: 0\n",
      "label for each of the below image: 7\n",
      "label for each of the below image: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# visualizing the first 10 images in the dataset and their labels\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(x_train[i].reshape(32, 32), cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    print('label for each of the below image: %s' % (np.argmax(y_train[0:10][i])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value before encoding: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Shape of y_train: (42000, 10, 10)\n",
      "One hot encoded value of y_train: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print(\"Value before encoding:\", y_train[0])\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"One hot encoded value of y_train:\", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "1. Dataset consists of 42000 test images of size 32 * 32.\n",
    "2. output consists of street images with numbers being displayed from 0-9\n",
    "3. Also The data has been split in 3 so that if desired accuracy is not achieved in training then we can try on validation set as well\n",
    "4. x_train and y_test contain greyscale RGB codes (from 0 to 255) while y_train and y_test contains labels from 0 to 9 which represents which number they actually are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Implement and apply a deep neural network classifier including (feedforward neural network, RELU, activations) (25 points)  \n",
    "### 5. Implement batch normalization for training the neural network(10 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Approach-1 \n",
    "##### 1. Model will have one input node  1, hidden node and 1 output node\n",
    "##### 2. Will test the model performance with and without batchnormalization, weight updation ,droupout.\n",
    "##### 3. If the model accuracy is not coming as expected then will increse the hidden layers\n",
    "##### 4. Also will heck the accuracy on normalized and normal  training values\n",
    "##### 5. If the accuracy on training set will not be measurable will make use of Validation set for training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. The Sequential model is a linear stack of layers.\n",
    "# 2. The model needs to know what input shape it should expect. For this reason, the first layer in a Sequential model\n",
    "# (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape.\n",
    "# 3. .fit() trains the model for a fixed number of epochs (iterations on a dataset)\n",
    "# 4. An epoch is an iteration over the entire x and y data provided\n",
    "# 5. batch_size is the number of samples per gradient update\n",
    "# 6. Will vary the hyperparameter to check for better accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_loop(iterations, lr, Lambda, x_train, verb=True):\n",
    "\n",
    "    #hyperparameters\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(1024,), activation='relu'))\n",
    "    model.add(Dense(hidden_nodes, activation='relu'))\n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=learning_rate)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])   \n",
    "    model.fit(x_train, y_train, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(x_train, y_train, verbose=0)\n",
    "    \n",
    "    # Fit the model   \n",
    "    return score, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 66.7021 - accuracy: 0.1047\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 29.9180 - accuracy: 0.1099: 0s - loss: 29.9180 - accuracy: 0.109\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 26.4629 - accuracy: 0.1094\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 24.1685 - accuracy: 0.1084\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 22.3945 - accuracy: 0.1092\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 20.9521 - accuracy: 0.1097\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 19.7756 - accuracy: 0.1116\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 18.8016 - accuracy: 0.1116\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 17.9734 - accuracy: 0.1132\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 17.2466 - accuracy: 0.1144\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 16.5986 - accuracy: 0.1152\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 16.0197 - accuracy: 0.1184\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 15.5007 - accuracy: 0.1186\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 15.0342 - accuracy: 0.1206\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 14.5880 - accuracy: 0.1220\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 14.1809 - accuracy: 0.1225\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 13.7802 - accuracy: 0.1238\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 13.4278 - accuracy: 0.1259\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 13.1198 - accuracy: 0.1277\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 12.7836 - accuracy: 0.1300\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 12.4907 - accuracy: 0.1311\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 12.2043 - accuracy: 0.1341\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 11.9435 - accuracy: 0.1365\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 11.6695 - accuracy: 0.1399\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 11.4321 - accuracy: 0.1424\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 11.1892 - accuracy: 0.1441: 0s - loss: 11.2196 - accura\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 11.0010 - accuracy: 0.1466\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 10.7816 - accuracy: 0.1496\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 10.5938 - accuracy: 0.1517\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 10.4155 - accuracy: 0.1530\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 10.2577 - accuracy: 0.1538\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 10.1015 - accuracy: 0.1568\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 9.9068 - accuracy: 0.1592\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 9.7659 - accuracy: 0.1619\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 9.6502 - accuracy: 0.1610\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 9.5149 - accuracy: 0.1635\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 9.4081 - accuracy: 0.1660 0s - los\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 9.2530 - accuracy: 0.1677\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 9.1574 - accuracy: 0.1684\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 9.0298 - accuracy: 0.1707\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.9024 - accuracy: 0.1723\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.8040 - accuracy: 0.1742\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 8.6914 - accuracy: 0.1757\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 8.6127 - accuracy: 0.1756\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.4972 - accuracy: 0.1776\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 8.4059 - accuracy: 0.1795\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.2834 - accuracy: 0.1815\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 8.2013 - accuracy: 0.1834\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.1513 - accuracy: 0.1828\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.0682 - accuracy: 0.1863\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.9563 - accuracy: 0.1871\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 7.8797 - accuracy: 0.1878\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.8185 - accuracy: 0.1898\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.7432 - accuracy: 0.1925\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 7.6781 - accuracy: 0.1917\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.6124 - accuracy: 0.1935\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.5181 - accuracy: 0.1965\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.4971 - accuracy: 0.1960\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.3915 - accuracy: 0.1985\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.3646 - accuracy: 0.1997\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.2650 - accuracy: 0.2018\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.2750 - accuracy: 0.2000\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.1584 - accuracy: 0.2040\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 7.1013 - accuracy: 0.2051\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.0371 - accuracy: 0.2048\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 7.0070 - accuracy: 0.2066\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 6.9260 - accuracy: 0.2081\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 6.9062 - accuracy: 0.2090\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 6.8325 - accuracy: 0.2097\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 6.8350 - accuracy: 0.2109\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 6.7539 - accuracy: 0.2117\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 6.7023 - accuracy: 0.2132\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 6.6385 - accuracy: 0.2160\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 6.6509 - accuracy: 0.2161\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 6.5458 - accuracy: 0.2187 0s - loss: 6.515\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 6.5328 - accuracy: 0.2182\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 6.5768 - accuracy: 0.2169 0s - l\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 6.4216 - accuracy: 0.2216\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 6.4212 - accuracy: 0.2216\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 24ms/step - loss: 6.3368 - accuracy: 0.2238 0s - l\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 6.3465 - accuracy: 0.2229 0s - loss: 6.3790 - accuracy: \n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 6.2915 - accuracy: 0.2252\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 6.2991 - accuracy: 0.2259\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 6.2373 - accuracy: 0.2273\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 6.1923 - accuracy: 0.2292\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 6.1351 - accuracy: 0.2285\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 6.1567 - accuracy: 0.2304\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 6.1503 - accuracy: 0.2301\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 6.0330 - accuracy: 0.2335\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 6.0601 - accuracy: 0.2302\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 5.9936 - accuracy: 0.2336\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 5.9126 - accuracy: 0.2388\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 5.9454 - accuracy: 0.2357\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 5.8920 - accuracy: 0.2371\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 5.9042 - accuracy: 0.2382\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 5.7818 - accuracy: 0.2418\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 5.7378 - accuracy: 0.2431\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 5.7149 - accuracy: 0.2437\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 5.6549 - accuracy: 0.2466\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 5.6914 - accuracy: 0.2443 0s - loss: 5.724\n",
      "Accuracy in training dataset: {0} 0.2478809505701065\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 5.7598 - accuracy: 0.2427\n",
      "Accuracy in test dataset : {0} 0.24272222816944122\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "Lambda = 0\n",
    "x_train = x_train.reshape(42000, 1024)\n",
    "x_test = x_test.reshape(18000, 1024)\n",
    "score, model = train_and_test_loop(100, lr, Lambda, x_train)\n",
    "print(\"Accuracy in training dataset: {0}\", score[1])\n",
    "testscore = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4354 - accuracy: 0.1035\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4342 - accuracy: 0.1035\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4330 - accuracy: 0.1035\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4318 - accuracy: 0.1035\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4306 - accuracy: 0.1033\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4295 - accuracy: 0.1033\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4284 - accuracy: 0.1036\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4272 - accuracy: 0.1038\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4262 - accuracy: 0.1040\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4251 - accuracy: 0.1040\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4240 - accuracy: 0.1042\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4230 - accuracy: 0.1043\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4219 - accuracy: 0.1044\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4209 - accuracy: 0.1045\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4199 - accuracy: 0.1046\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4189 - accuracy: 0.1045\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4180 - accuracy: 0.1045\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4170 - accuracy: 0.1047\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4161 - accuracy: 0.1048\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4152 - accuracy: 0.1047\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4142 - accuracy: 0.1048\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4133 - accuracy: 0.1049\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.4125 - accuracy: 0.1052\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4116 - accuracy: 0.1053\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4107 - accuracy: 0.1051\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4099 - accuracy: 0.1053\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4090 - accuracy: 0.1052\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4082 - accuracy: 0.1054\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4074 - accuracy: 0.1054\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4066 - accuracy: 0.1053\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4058 - accuracy: 0.1051\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4050 - accuracy: 0.1052\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4043 - accuracy: 0.1052\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4035 - accuracy: 0.1051\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 2.4027 - accuracy: 0.1053\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 2.4020 - accuracy: 0.1055\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.4013 - accuracy: 0.1055\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.4006 - accuracy: 0.1055\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 2.3998 - accuracy: 0.1057\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3991 - accuracy: 0.1056\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3984 - accuracy: 0.1055\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3978 - accuracy: 0.1055\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3971 - accuracy: 0.1055\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3964 - accuracy: 0.1055\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3957 - accuracy: 0.1055\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3951 - accuracy: 0.1057\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3945 - accuracy: 0.1057\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3938 - accuracy: 0.1057 0s - l\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3932 - accuracy: 0.1058\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3926 - accuracy: 0.1059\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3920 - accuracy: 0.1057\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3913 - accuracy: 0.1057\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3907 - accuracy: 0.1058\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3902 - accuracy: 0.1059\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3896 - accuracy: 0.1058\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3890 - accuracy: 0.1059\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3884 - accuracy: 0.1060\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3879 - accuracy: 0.1058\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3873 - accuracy: 0.1060\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3867 - accuracy: 0.1060\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3862 - accuracy: 0.1061 0s - loss: 2\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3857 - accuracy: 0.1061\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3851 - accuracy: 0.1063\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3846 - accuracy: 0.1062\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3841 - accuracy: 0.1062\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3836 - accuracy: 0.1064\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3831 - accuracy: 0.1064\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3825 - accuracy: 0.1063\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3820 - accuracy: 0.1065\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3816 - accuracy: 0.1067\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3811 - accuracy: 0.1069\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3806 - accuracy: 0.1067\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3801 - accuracy: 0.1068\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3796 - accuracy: 0.1067\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 2.3792 - accuracy: 0.1068\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3787 - accuracy: 0.1067\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3782 - accuracy: 0.1068\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3778 - accuracy: 0.1069\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3773 - accuracy: 0.1069\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3769 - accuracy: 0.1070\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3765 - accuracy: 0.1068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3760 - accuracy: 0.1069\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3756 - accuracy: 0.1070\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3752 - accuracy: 0.1071\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3748 - accuracy: 0.1070\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3743 - accuracy: 0.1069\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.3738 - accuracy: 0.10 - 1s 25ms/step - loss: 2.3739 - accuracy: 0.1070\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3735 - accuracy: 0.1069\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3731 - accuracy: 0.1071\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3727 - accuracy: 0.1071\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3723 - accuracy: 0.1072 0s - loss: 2.3725 - accuracy: 0.\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3719 - accuracy: 0.1072\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3715 - accuracy: 0.1073\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3712 - accuracy: 0.1074\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 2.3708 - accuracy: 0.1075\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 2.3704 - accuracy: 0.1078\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 2.3700 - accuracy: 0.1077\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 2.3697 - accuracy: 0.1075\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 2.3693 - accuracy: 0.1077\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 2.3689 - accuracy: 0.1077\n",
      "Accuracy in training dataset: {0} 0.10766666382551193\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2.3717 - accuracy: 0.1042\n",
      "Accuracy in test dataset : {0} 0.1041666641831398\n"
     ]
    }
   ],
   "source": [
    "# using normalized value\n",
    "lr = 0.00001\n",
    "Lambda = 0\n",
    "X_train_normalize, x_test_normalize, x_val_normalize = Normalize(x_train, x_test, x_val)\n",
    "score, model = train_and_test_loop(100, lr, Lambda,X_train_normalize)\n",
    "print(\"Accuracy in training dataset: {0}\", score[1])\n",
    "testscore = model.evaluate(x_test_normalize, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "1. Loss barely changing. Learning rate is probably too low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Weight Updation on Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight Updation\n",
    "def train_and_test_loop_withWeightUpdation(iterations, lr, Lambda, x_train, verb=True):\n",
    "     #hyperparameters\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(1024,), activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(hidden_nodes, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=learning_rate)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train, y_train, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(x_train, y_train, verbose=0)\n",
    "    \n",
    "    # Fit the model   \n",
    "    return score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.5294 - accuracy: 0.0999\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.5246 - accuracy: 0.0998\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.5199 - accuracy: 0.0998\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.5154 - accuracy: 0.0995\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.5111 - accuracy: 0.0995\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.5070 - accuracy: 0.0995\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.5030 - accuracy: 0.0996\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4992 - accuracy: 0.0996\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4955 - accuracy: 0.0996\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4920 - accuracy: 0.0995\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4886 - accuracy: 0.0995\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4853 - accuracy: 0.0998\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4822 - accuracy: 0.0998\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4791 - accuracy: 0.0993\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4762 - accuracy: 0.0993\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4734 - accuracy: 0.0994\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4706 - accuracy: 0.0995\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4680 - accuracy: 0.0994\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4655 - accuracy: 0.0993\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4630 - accuracy: 0.0992\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4606 - accuracy: 0.0989\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4584 - accuracy: 0.0990\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4561 - accuracy: 0.0991\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4540 - accuracy: 0.0990\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4519 - accuracy: 0.0989 0s - loss: 2.4519 - accuracy: 0.09\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4499 - accuracy: 0.0988\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4480 - accuracy: 0.0987\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4461 - accuracy: 0.0986\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4442 - accuracy: 0.0985\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4425 - accuracy: 0.0987\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4408 - accuracy: 0.0986 0s - los\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4391 - accuracy: 0.0987\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4375 - accuracy: 0.0986\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4359 - accuracy: 0.0988\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4344 - accuracy: 0.0986\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4329 - accuracy: 0.0985\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4315 - accuracy: 0.0987\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4301 - accuracy: 0.0986\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4288 - accuracy: 0.0987\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4275 - accuracy: 0.0987\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4262 - accuracy: 0.0988\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4250 - accuracy: 0.0987\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4238 - accuracy: 0.0990\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4226 - accuracy: 0.0991\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4215 - accuracy: 0.0990\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4204 - accuracy: 0.0991\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4193 - accuracy: 0.0991\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4183 - accuracy: 0.0992\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4173 - accuracy: 0.0992\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4163 - accuracy: 0.0992\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4154 - accuracy: 0.0990\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4144 - accuracy: 0.0988\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4135 - accuracy: 0.0986\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4126 - accuracy: 0.0986\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4118 - accuracy: 0.0988\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4110 - accuracy: 0.0988\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4101 - accuracy: 0.0987\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4093 - accuracy: 0.0985\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4086 - accuracy: 0.0983\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4078 - accuracy: 0.0983\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4071 - accuracy: 0.0985\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4064 - accuracy: 0.0985\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4057 - accuracy: 0.0985\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4050 - accuracy: 0.0988\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4043 - accuracy: 0.0987\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4037 - accuracy: 0.0985\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4031 - accuracy: 0.0987\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4025 - accuracy: 0.0986\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4019 - accuracy: 0.0987\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.4013 - accuracy: 0.0988\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4007 - accuracy: 0.0986\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.4002 - accuracy: 0.0985\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 2.3996 - accuracy: 0.0984\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3991 - accuracy: 0.0984 0s - loss:\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3986 - accuracy: 0.0983\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3981 - accuracy: 0.0980\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3976 - accuracy: 0.0979\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3971 - accuracy: 0.0979\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3966 - accuracy: 0.0979 0s - loss: 2.3982 \n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3962 - accuracy: 0.0978\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3957 - accuracy: 0.0977\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3953 - accuracy: 0.0978\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 2.3949 - accuracy: 0.0978\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3944 - accuracy: 0.0978\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3940 - accuracy: 0.0980\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 2.3936 - accuracy: 0.0979\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3932 - accuracy: 0.0980\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3929 - accuracy: 0.0979\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 2.3925 - accuracy: 0.0978\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 2.3921 - accuracy: 0.0979\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3918 - accuracy: 0.0978\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3914 - accuracy: 0.0977\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3911 - accuracy: 0.0976\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3908 - accuracy: 0.0977\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 2.3904 - accuracy: 0.0976\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3901 - accuracy: 0.0975\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3898 - accuracy: 0.0974\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3895 - accuracy: 0.0974\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3892 - accuracy: 0.0973\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 2.3889 - accuracy: 0.0972\n",
      "Accuracy in training dataset: {0} 0.09730952233076096\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2.3888 - accuracy: 0.0950\n",
      "Accuracy in test dataset : {0} 0.0949999988079071\n"
     ]
    }
   ],
   "source": [
    "#using normalized values\n",
    "lr = 0.00001\n",
    "Lambda = 0\n",
    "X_train_normalize, x_test_normalize, x_val_normalize = Normalize(x_train, x_test, x_val)\n",
    "score, model = train_and_test_loop_withWeightUpdation(100, lr, Lambda,X_train_normalize)\n",
    "print(\"Accuracy in training dataset: {0}\", score[1])\n",
    "testscore = model.evaluate(x_test_normalize, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 92.6300 - accuracy: 0.1013: 0s - loss: 117.0327 - accu\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 38.9673 - accuracy: 0.1039\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 34.1637 - accuracy: 0.1080\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 30.9039 - accuracy: 0.1113: 0s - loss: 32.7309 - ac\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 28.4558 - accuracy: 0.1152\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 26.5250 - accuracy: 0.1198\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 24.9825 - accuracy: 0.1230\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 23.7238 - accuracy: 0.1265\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 22.6911 - accuracy: 0.1286\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 21.8466 - accuracy: 0.1313\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 21.0879 - accuracy: 0.1338\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 20.4067 - accuracy: 0.1373\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 19.8169 - accuracy: 0.1392: 0s - loss: 19.9031 - accuracy: 0\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 19.3309 - accuracy: 0.1402\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 18.8294 - accuracy: 0.1422\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 18.3847 - accuracy: 0.1445\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 17.9647 - accuracy: 0.1457\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 17.5742 - accuracy: 0.1487\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 17.2274 - accuracy: 0.1506\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 16.8251 - accuracy: 0.1540\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 16.4759 - accuracy: 0.1559\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 16.1805 - accuracy: 0.1581\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 15.8629 - accuracy: 0.1622\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 15.5596 - accuracy: 0.1632\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 15.2795 - accuracy: 0.1667\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 14.9832 - accuracy: 0.1676\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 14.7523 - accuracy: 0.1698\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 14.5723 - accuracy: 0.1705\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 14.1905 - accuracy: 0.1742\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 14.0381 - accuracy: 0.1762\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 13.8970 - accuracy: 0.1774\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 13.6628 - accuracy: 0.1808\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 13.4430 - accuracy: 0.1804\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 13.1824 - accuracy: 0.1851\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 13.0172 - accuracy: 0.1870\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 12.8197 - accuracy: 0.1890\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 12.6446 - accuracy: 0.1914\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 12.5525 - accuracy: 0.1928\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 12.4212 - accuracy: 0.1944\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 12.1370 - accuracy: 0.1983\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 12.0480 - accuracy: 0.1982\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 11.8886 - accuracy: 0.2006\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 11.7219 - accuracy: 0.2035\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 11.5801 - accuracy: 0.2059\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 11.4578 - accuracy: 0.2065\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 11.3269 - accuracy: 0.2077\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 11.2602 - accuracy: 0.2094\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 11.1438 - accuracy: 0.2111\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 10.9751 - accuracy: 0.2139\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 10.8527 - accuracy: 0.2161\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 10.6682 - accuracy: 0.2188\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 10.5942 - accuracy: 0.2194\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 10.4288 - accuracy: 0.2212\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 10.3402 - accuracy: 0.2224\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 10.3218 - accuracy: 0.2238\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 10.1889 - accuracy: 0.2255\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 10.1489 - accuracy: 0.2247\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 10.0362 - accuracy: 0.2277\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 9.8958 - accuracy: 0.2295\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 9.8243 - accuracy: 0.2314\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 9.7860 - accuracy: 0.2305\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 9.6520 - accuracy: 0.2320\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 9.6280 - accuracy: 0.2356\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 9.4905 - accuracy: 0.2365\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 9.5006 - accuracy: 0.2358\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 9.3013 - accuracy: 0.2403\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 9.2227 - accuracy: 0.2415\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 9.1544 - accuracy: 0.2417\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 9.1885 - accuracy: 0.2431\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 9.0527 - accuracy: 0.2464\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.9607 - accuracy: 0.2471 0s - loss: 8.8563 \n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.9863 - accuracy: 0.2491\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.9506 - accuracy: 0.2502\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.7661 - accuracy: 0.2500\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.6661 - accuracy: 0.2531\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.7332 - accuracy: 0.2512\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.5024 - accuracy: 0.2582\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.4282 - accuracy: 0.2585\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 8.4224 - accuracy: 0.2580\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 23ms/step - loss: 8.4753 - accuracy: 0.2594\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 8.3599 - accuracy: 0.2594\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.3086 - accuracy: 0.2615\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.2910 - accuracy: 0.2605\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.1010 - accuracy: 0.2663\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.0351 - accuracy: 0.2665\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.1630 - accuracy: 0.2660\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.0571 - accuracy: 0.2675\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 8.0392 - accuracy: 0.2676\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 8.0096 - accuracy: 0.2670\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 7.8698 - accuracy: 0.2710\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.9491 - accuracy: 0.2712\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.7826 - accuracy: 0.2718\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.7902 - accuracy: 0.2725\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 7.7063 - accuracy: 0.2777\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.6837 - accuracy: 0.2751\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 7.7390 - accuracy: 0.2732\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 7.5897 - accuracy: 0.2775\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.5892 - accuracy: 0.2774\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.5435 - accuracy: 0.2786\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 7.4103 - accuracy: 0.2826\n",
      "Accuracy in training dataset: {0} 0.28740477561950684\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 7.4116 - accuracy: 0.2809\n",
      "Accuracy in test dataset : {0} 0.28094443678855896\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "Lambda = 0\n",
    "x_train = x_train.reshape(42000, 1024)\n",
    "x_test = x_test.reshape(18000, 1024)\n",
    "score, model = train_and_test_loop_withWeightUpdation(100, lr, Lambda,x_train)\n",
    "print(\"Accuracy in training dataset: {0}\", score[1])\n",
    "testscore = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "1. Weight initialization is not working on approach 1.\n",
    "2. The accuracy is not even measurable. Also the accuracy is consistently reducing in caseof training data set\n",
    "3. loss is superbly high when we use normalized value of x train \n",
    "4. Loss barely changing. Learning rate is probably too low. Lets change in next iteration\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchNormalization on Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_test_loop_withBatchNormalization(iterations, lr, Lambda, x_train, verb=True):\n",
    "\n",
    "     #hyperparameters\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(1024,)))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu'))  \n",
    "    model.add(Dense(hidden_nodes))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu'))  \n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(x_train, y_train, verbose=0)\n",
    "    \n",
    "    # Fit the model   \n",
    "    return score, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.5169 - accuracy: 0.1016\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.5037 - accuracy: 0.1024\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.4895 - accuracy: 0.1025\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 4.4766 - accuracy: 0.1039\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.4642 - accuracy: 0.1040\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.4527 - accuracy: 0.1043\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 4.4400 - accuracy: 0.1053\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.4290 - accuracy: 0.1059\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.4174 - accuracy: 0.1060\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.4066 - accuracy: 0.1075\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.3969 - accuracy: 0.1076\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.3866 - accuracy: 0.1087\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.3767 - accuracy: 0.1086\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.3673 - accuracy: 0.1096\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.3576 - accuracy: 0.1097\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 4.3489 - accuracy: 0.1107\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.3396 - accuracy: 0.1111\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.3306 - accuracy: 0.1119\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.3224 - accuracy: 0.1124\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.3139 - accuracy: 0.1123\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.3056 - accuracy: 0.1136\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.2973 - accuracy: 0.1141\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 4.2897 - accuracy: 0.1148\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.2815 - accuracy: 0.1151\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.2739 - accuracy: 0.1158\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.2661 - accuracy: 0.1180\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.2589 - accuracy: 0.1180\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.2520 - accuracy: 0.1187\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 4.2442 - accuracy: 0.1193\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.2370 - accuracy: 0.1203\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.2302 - accuracy: 0.1207\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.2230 - accuracy: 0.1210\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.2162 - accuracy: 0.1235\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.2092 - accuracy: 0.1227\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.2023 - accuracy: 0.1226\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.1956 - accuracy: 0.1243\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.1893 - accuracy: 0.1259\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.1825 - accuracy: 0.1263\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.1767 - accuracy: 0.1270\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.1697 - accuracy: 0.1274\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.1634 - accuracy: 0.1281\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 4.1570 - accuracy: 0.1287\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 4.1509 - accuracy: 0.1294\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.1450 - accuracy: 0.1308\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.1386 - accuracy: 0.13 - 1s 35ms/step - loss: 4.1384 - accuracy: 0.1327\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.1326 - accuracy: 0.1326\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.1267 - accuracy: 0.1336\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.1206 - accuracy: 0.1334\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.1147 - accuracy: 0.1348\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 4.1089 - accuracy: 0.1354\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.1032 - accuracy: 0.1355\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.0974 - accuracy: 0.1372\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.0917 - accuracy: 0.1384\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.0864 - accuracy: 0.1388\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 4.0806 - accuracy: 0.1406\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.0748 - accuracy: 0.1391\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.0688 - accuracy: 0.1414\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.0639 - accuracy: 0.1426\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.0583 - accuracy: 0.1438\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.0530 - accuracy: 0.1440\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.0473 - accuracy: 0.1439\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.0417 - accuracy: 0.1450\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.0368 - accuracy: 0.1466\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.0310 - accuracy: 0.1473\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.0261 - accuracy: 0.1482\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.0205 - accuracy: 0.1485\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.0155 - accuracy: 0.1497\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 4.0104 - accuracy: 0.1502\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 4.0057 - accuracy: 0.1507\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3.9999 - accuracy: 0.1518\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3.9951 - accuracy: 0.1530\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3.9901 - accuracy: 0.1534\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 3.9853 - accuracy: 0.1549\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3.9802 - accuracy: 0.1549\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 3.9756 - accuracy: 0.1567\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3.9703 - accuracy: 0.1568\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3.9653 - accuracy: 0.1570\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 3.9605 - accuracy: 0.1581\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 3.9555 - accuracy: 0.1589\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3.9505 - accuracy: 0.1603\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 36ms/step - loss: 3.9459 - accuracy: 0.1602\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 3.9409 - accuracy: 0.1617\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3.9361 - accuracy: 0.1622\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3.9317 - accuracy: 0.1634\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3.9270 - accuracy: 0.1644\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3.9224 - accuracy: 0.1649\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3.9178 - accuracy: 0.1661\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3.9128 - accuracy: 0.1668\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3.9082 - accuracy: 0.1690\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3.9041 - accuracy: 0.1686\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3.8990 - accuracy: 0.1700\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3.8947 - accuracy: 0.1715\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 3.8900 - accuracy: 0.1707\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3.8855 - accuracy: 0.1717\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3.8813 - accuracy: 0.1727\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3.8763 - accuracy: 0.1740\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3.8719 - accuracy: 0.1758\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3.8676 - accuracy: 0.1764\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3.8634 - accuracy: 0.1762\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 3.8589 - accuracy: 0.1765\n",
      "Accuracy in training dataset: {0} 0.17790475487709045\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3.8580 - accuracy: 0.1797\n",
      "Accuracy in test dataset : {0} 0.179666668176651\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "Lambda = .1\n",
    "x_train = x_train.reshape(42000, 1024)\n",
    "x_test = x_test.reshape(18000, 1024)\n",
    "score, model = train_and_test_loop_withBatchNormalization(100, lr, Lambda, x_train)\n",
    "print(\"Accuracy in training dataset: {0}\", score[1])\n",
    "testscore = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 3.3241 - accuracy: 0.2771\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 2.0381 - accuracy: 0.5332\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.7612 - accuracy: 0.6065\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.6219 - accuracy: 0.6490\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.5207 - accuracy: 0.6764\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.4412 - accuracy: 0.6940\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.3734 - accuracy: 0.7119\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.3186 - accuracy: 0.7242\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.2680 - accuracy: 0.7366\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2200 - accuracy: 0.7507\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1795 - accuracy: 0.7599\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.1429 - accuracy: 0.7708\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1090 - accuracy: 0.7783\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.0807 - accuracy: 0.7861\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.0523 - accuracy: 0.7937\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0281 - accuracy: 0.8003\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 1.0007 - accuracy: 0.8065\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.9802 - accuracy: 0.8121\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.9657 - accuracy: 0.8139\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.9449 - accuracy: 0.8214\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.9313 - accuracy: 0.8238\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.9106 - accuracy: 0.8295\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8970 - accuracy: 0.8321\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8839 - accuracy: 0.8374\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8685 - accuracy: 0.8409\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8567 - accuracy: 0.8416\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8440 - accuracy: 0.8466\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8395 - accuracy: 0.8450\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8257 - accuracy: 0.8481\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8165 - accuracy: 0.8508\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8072 - accuracy: 0.8523\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7984 - accuracy: 0.8555\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7869 - accuracy: 0.8593\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7798 - accuracy: 0.8578\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.7796 - accuracy: 0.8578\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7644 - accuracy: 0.8630\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7630 - accuracy: 0.8610\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7498 - accuracy: 0.8654\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7455 - accuracy: 0.8656\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7335 - accuracy: 0.8709\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7308 - accuracy: 0.8695\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7249 - accuracy: 0.8709\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7250 - accuracy: 0.8698\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7175 - accuracy: 0.8700\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7105 - accuracy: 0.8741\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7009 - accuracy: 0.8762\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7016 - accuracy: 0.8744\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6963 - accuracy: 0.8763\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6861 - accuracy: 0.8790\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6813 - accuracy: 0.8809\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6774 - accuracy: 0.8816\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6754 - accuracy: 0.8815\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6747 - accuracy: 0.8804\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6719 - accuracy: 0.8802\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6640 - accuracy: 0.8831\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6588 - accuracy: 0.8837\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.6549 - accuracy: 0.8856\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.6514 - accuracy: 0.8871\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.6451 - accuracy: 0.8888\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6473 - accuracy: 0.8858\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6412 - accuracy: 0.8878\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6351 - accuracy: 0.8903\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6291 - accuracy: 0.8910\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6274 - accuracy: 0.8926\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6304 - accuracy: 0.8902\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.6281 - accuracy: 0.8892\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.6212 - accuracy: 0.8922\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6120 - accuracy: 0.8954\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6114 - accuracy: 0.8959\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6118 - accuracy: 0.8943\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6001 - accuracy: 0.8996\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5980 - accuracy: 0.8993\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5976 - accuracy: 0.8982\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5965 - accuracy: 0.8992\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5927 - accuracy: 0.8984\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.5852 - accuracy: 0.9026\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5878 - accuracy: 0.8995\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5843 - accuracy: 0.9016\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.5830 - accuracy: 0.9013\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5784 - accuracy: 0.9038\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5787 - accuracy: 0.9031\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5736 - accuracy: 0.9034\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5736 - accuracy: 0.9037\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.5635 - accuracy: 0.9086\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5622 - accuracy: 0.9070\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5628 - accuracy: 0.9065\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.5575 - accuracy: 0.9083\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.5556 - accuracy: 0.9079\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5569 - accuracy: 0.9075\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5503 - accuracy: 0.9112\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.5512 - accuracy: 0.9098\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5486 - accuracy: 0.9100\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5472 - accuracy: 0.9098\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5460 - accuracy: 0.9096\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.5477 - accuracy: 0.9093\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5409 - accuracy: 0.9109\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5386 - accuracy: 0.9114\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.5366 - accuracy: 0.9118\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5345 - accuracy: 0.9121\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.5339 - accuracy: 0.9112\n",
      "Accuracy in training dataset: {0} 0.8558095097541809\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 0.8156 - accuracy: 0.8005\n",
      "Accuracy in test dataset : {0} 0.8004999756813049\n"
     ]
    }
   ],
   "source": [
    "# changing value of learning rate to check the impact \n",
    "lr = 0.01\n",
    "Lambda = .1\n",
    "x_train = x_train.reshape(42000, 1024)\n",
    "x_test = x_test.reshape(18000, 1024)\n",
    "score, model = train_and_test_loop_withBatchNormalization(100, lr, Lambda,x_train)\n",
    "print(\"Accuracy in training dataset: {0}\", score[1])\n",
    "testscore = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 3.4245 - accuracy: 0.1733\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 2.2832 - accuracy: 0.3044\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.0974 - accuracy: 0.3451\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 2.0218 - accuracy: 0.3736\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.9667 - accuracy: 0.3938\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 1.9232 - accuracy: 0.4128\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.8848 - accuracy: 0.4269\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.8522 - accuracy: 0.4373\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 1.8233 - accuracy: 0.4488\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 1.7956 - accuracy: 0.4552\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.7724 - accuracy: 0.4633\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.7511 - accuracy: 0.4697\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.7302 - accuracy: 0.4762\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.7117 - accuracy: 0.4797\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.6945 - accuracy: 0.4842\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.6776 - accuracy: 0.4883\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.6622 - accuracy: 0.4924\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.6481 - accuracy: 0.4978\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.6325 - accuracy: 0.5033\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.6187 - accuracy: 0.5087\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 1.6057 - accuracy: 0.5113\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.5939 - accuracy: 0.5133\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.5809 - accuracy: 0.5190\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.5690 - accuracy: 0.5228\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.5576 - accuracy: 0.5260\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.5465 - accuracy: 0.5291\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.5352 - accuracy: 0.5334\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.5251 - accuracy: 0.5360\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.5145 - accuracy: 0.5399\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.5045 - accuracy: 0.5426\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.4952 - accuracy: 0.5462\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.4851 - accuracy: 0.5480\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.4760 - accuracy: 0.5513\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.4679 - accuracy: 0.5564\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.4587 - accuracy: 0.5576\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.4503 - accuracy: 0.5613\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.4408 - accuracy: 0.5647\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.4337 - accuracy: 0.5688\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.4249 - accuracy: 0.5707\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.4166 - accuracy: 0.5726\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.4094 - accuracy: 0.5753\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.4019 - accuracy: 0.5773\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 1.3954 - accuracy: 0.5790\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.3866 - accuracy: 0.5827\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.3799 - accuracy: 0.5852\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.3727 - accuracy: 0.5874\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.3644 - accuracy: 0.5904\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.3583 - accuracy: 0.5935\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.3526 - accuracy: 0.5940\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.3456 - accuracy: 0.5974\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.3399 - accuracy: 0.5999\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.3326 - accuracy: 0.6031\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.3263 - accuracy: 0.6049\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.3209 - accuracy: 0.6074\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.3139 - accuracy: 0.6090\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.3078 - accuracy: 0.6124\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.3024 - accuracy: 0.6132\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2950 - accuracy: 0.6159\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.2881 - accuracy: 0.6200\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2835 - accuracy: 0.6198\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2790 - accuracy: 0.6209\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2707 - accuracy: 0.6261\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 1.2642 - accuracy: 0.6281\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2597 - accuracy: 0.6294\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2533 - accuracy: 0.6319\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2498 - accuracy: 0.6351\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2438 - accuracy: 0.6341\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2363 - accuracy: 0.6393\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2318 - accuracy: 0.6412\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2268 - accuracy: 0.6442\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2215 - accuracy: 0.6435\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2155 - accuracy: 0.6459\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2095 - accuracy: 0.6486\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.2052 - accuracy: 0.6516\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.2017 - accuracy: 0.6508\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 1.1964 - accuracy: 0.6535\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 1.1930 - accuracy: 0.6545\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 1.1851 - accuracy: 0.6595\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.1790 - accuracy: 0.6611\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.1740 - accuracy: 0.6626\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.1667 - accuracy: 0.6658\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 34ms/step - loss: 1.1631 - accuracy: 0.6682\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.1579 - accuracy: 0.6698\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.1528 - accuracy: 0.6709\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.1475 - accuracy: 0.6723\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.1472 - accuracy: 0.6723\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.1405 - accuracy: 0.6773\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.1353 - accuracy: 0.6759\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.1321 - accuracy: 0.6774\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.1277 - accuracy: 0.6806\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.1199 - accuracy: 0.6831\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.1166 - accuracy: 0.6842\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.1118 - accuracy: 0.6882\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.1081 - accuracy: 0.6863\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.1010 - accuracy: 0.6899\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.0969 - accuracy: 0.6920\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.0960 - accuracy: 0.6930\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.0931 - accuracy: 0.6910\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.0849 - accuracy: 0.6951\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.0804 - accuracy: 0.6990\n",
      "Accuracy in training dataset: {0} 0.6914523839950562\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 1.5919 - accuracy: 0.4940\n",
      "Accuracy in test dataset : {0} 0.8004999756813049\n"
     ]
    }
   ],
   "source": [
    "# using normalized values along with updated learning rate to check the impact \n",
    "lr = 0.01\n",
    "Lambda = .1\n",
    "X_train_normalize, x_test_normalize, x_val_normalize = Normalize(x_train, x_test, x_val)\n",
    "score, model = train_and_test_loop_withBatchNormalization(100, lr, Lambda, X_train_normalize)\n",
    "print(\"Accuracy in training dataset: {0}\", score[1])\n",
    "result = model.evaluate(x_test_normalize, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "1.  Batch normalization with updated value of learning rate improved accuracy to 91 percent in training but it seems the model is becoming overfit. We will try to reduce the overfitting by adding dropout layers\n",
    "2. Normalized values are reducing the model accuracy and increases the loss\n",
    "3. Changing(Reducing Learning rate) has improved the accuracy to a considerable percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Dropouts on approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding 1 droupout\n",
    "def train_and_test_loop_withOneDropouts(iterations,lr, Lambda, x_train, verb=True):\n",
    "\n",
    "     #hyperparameters\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "      \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(1024,)))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu'))  \n",
    "    \n",
    "    model.add(Dense(hidden_nodes))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=learning_rate)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer= sgd , metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(x_train, y_train, verbose=0)\n",
    "    \n",
    "    # Fit the model   \n",
    "    return score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 4.2649 - accuracy: 0.1364\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 3.7286 - accuracy: 0.1982\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 3.3766 - accuracy: 0.2536\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 3.0939 - accuracy: 0.3031\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 2.8674 - accuracy: 0.3482\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 2.6798 - accuracy: 0.3893\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 2.5295 - accuracy: 0.4233\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 2.4023 - accuracy: 0.4524\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 2.2975 - accuracy: 0.4806\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 2.2090 - accuracy: 0.5025\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 2.1356 - accuracy: 0.5211\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 2.0704 - accuracy: 0.5386\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 2.0151 - accuracy: 0.5551\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.9676 - accuracy: 0.5654\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.9281 - accuracy: 0.5768\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.8910 - accuracy: 0.5853\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.8561 - accuracy: 0.5948\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.8267 - accuracy: 0.6048\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.8012 - accuracy: 0.6084\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.7740 - accuracy: 0.6176\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.7525 - accuracy: 0.6231\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.7308 - accuracy: 0.6277\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.7097 - accuracy: 0.6327\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.6934 - accuracy: 0.6359\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.6744 - accuracy: 0.6426\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.6588 - accuracy: 0.6463\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.6447 - accuracy: 0.6473\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.6278 - accuracy: 0.6521\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.6142 - accuracy: 0.6555\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.6016 - accuracy: 0.6592\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.5900 - accuracy: 0.6599\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.5769 - accuracy: 0.6648\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.5638 - accuracy: 0.6701\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.5527 - accuracy: 0.6719\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.5416 - accuracy: 0.6729\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.5309 - accuracy: 0.6764\n",
      "Epoch 37/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.5208 - accuracy: 0.6760\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.5101 - accuracy: 0.6821\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.5009 - accuracy: 0.6819\n",
      "Epoch 40/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.4913 - accuracy: 0.6870\n",
      "Epoch 41/200\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.4828 - accuracy: 0.6867\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.4729 - accuracy: 0.6907\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.4644 - accuracy: 0.6934\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.4553 - accuracy: 0.6955\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.4474 - accuracy: 0.6960\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.4391 - accuracy: 0.6990\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.4313 - accuracy: 0.7010\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.4242 - accuracy: 0.7013\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.4158 - accuracy: 0.7045\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.4091 - accuracy: 0.7075\n",
      "Epoch 51/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.4011 - accuracy: 0.7093\n",
      "Epoch 52/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3949 - accuracy: 0.7104\n",
      "Epoch 53/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3852 - accuracy: 0.7107\n",
      "Epoch 54/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3801 - accuracy: 0.7136\n",
      "Epoch 55/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3723 - accuracy: 0.7144\n",
      "Epoch 56/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3653 - accuracy: 0.7161\n",
      "Epoch 57/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3587 - accuracy: 0.7185\n",
      "Epoch 58/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3543 - accuracy: 0.7185\n",
      "Epoch 59/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.3474 - accuracy: 0.7209\n",
      "Epoch 60/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.3406 - accuracy: 0.7229\n",
      "Epoch 61/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.3343 - accuracy: 0.7243\n",
      "Epoch 62/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3274 - accuracy: 0.7269\n",
      "Epoch 63/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.3227 - accuracy: 0.7279\n",
      "Epoch 64/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3163 - accuracy: 0.7284\n",
      "Epoch 65/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.3112 - accuracy: 0.7300\n",
      "Epoch 66/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.3035 - accuracy: 0.7341\n",
      "Epoch 67/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.2999 - accuracy: 0.7336\n",
      "Epoch 68/200\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.2919 - accuracy: 0.7346\n",
      "Epoch 69/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2872 - accuracy: 0.7367\n",
      "Epoch 70/200\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.2827 - accuracy: 0.7367\n",
      "Epoch 71/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.2762 - accuracy: 0.7406\n",
      "Epoch 72/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.2724 - accuracy: 0.7395\n",
      "Epoch 73/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.2679 - accuracy: 0.7404\n",
      "Epoch 74/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.2612 - accuracy: 0.7440\n",
      "Epoch 75/200\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.2579 - accuracy: 0.7444\n",
      "Epoch 76/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.2521 - accuracy: 0.7455\n",
      "Epoch 77/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.2458 - accuracy: 0.7452\n",
      "Epoch 78/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2422 - accuracy: 0.7481\n",
      "Epoch 79/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2368 - accuracy: 0.7488\n",
      "Epoch 80/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2314 - accuracy: 0.7525\n",
      "Epoch 81/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2281 - accuracy: 0.7528\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 1.2231 - accuracy: 0.7545\n",
      "Epoch 83/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.2168 - accuracy: 0.7569\n",
      "Epoch 84/200\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.2129 - accuracy: 0.7560 1s -\n",
      "Epoch 85/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.2097 - accuracy: 0.7565\n",
      "Epoch 86/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.2037 - accuracy: 0.7586\n",
      "Epoch 87/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2002 - accuracy: 0.7600\n",
      "Epoch 88/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1953 - accuracy: 0.7593\n",
      "Epoch 89/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1907 - accuracy: 0.7614\n",
      "Epoch 90/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1885 - accuracy: 0.7619\n",
      "Epoch 91/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1822 - accuracy: 0.7644\n",
      "Epoch 92/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1794 - accuracy: 0.7638\n",
      "Epoch 93/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1742 - accuracy: 0.7660\n",
      "Epoch 94/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1713 - accuracy: 0.7664\n",
      "Epoch 95/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1662 - accuracy: 0.7677\n",
      "Epoch 96/200\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.1612 - accuracy: 0.7695\n",
      "Epoch 97/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1600 - accuracy: 0.7700\n",
      "Epoch 98/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1546 - accuracy: 0.7715\n",
      "Epoch 99/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1508 - accuracy: 0.7712\n",
      "Epoch 100/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1471 - accuracy: 0.7727\n",
      "Epoch 101/200\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.1434 - accuracy: 0.7740\n",
      "Epoch 102/200\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.1386 - accuracy: 0.7747\n",
      "Epoch 103/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.1362 - accuracy: 0.7754\n",
      "Epoch 104/200\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.1328 - accuracy: 0.7771\n",
      "Epoch 105/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1286 - accuracy: 0.7775\n",
      "Epoch 106/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1234 - accuracy: 0.7792\n",
      "Epoch 107/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1206 - accuracy: 0.7804\n",
      "Epoch 108/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1170 - accuracy: 0.7788\n",
      "Epoch 109/200\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.1136 - accuracy: 0.7796\n",
      "Epoch 110/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1119 - accuracy: 0.7820\n",
      "Epoch 111/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1069 - accuracy: 0.7847\n",
      "Epoch 112/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1044 - accuracy: 0.7844\n",
      "Epoch 113/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0994 - accuracy: 0.7855\n",
      "Epoch 114/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0947 - accuracy: 0.7873\n",
      "Epoch 115/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0938 - accuracy: 0.7861\n",
      "Epoch 116/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0900 - accuracy: 0.7874\n",
      "Epoch 117/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0884 - accuracy: 0.7868\n",
      "Epoch 118/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0835 - accuracy: 0.7896\n",
      "Epoch 119/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0814 - accuracy: 0.7901\n",
      "Epoch 120/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0773 - accuracy: 0.7915\n",
      "Epoch 121/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0738 - accuracy: 0.7921\n",
      "Epoch 122/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0723 - accuracy: 0.7928\n",
      "Epoch 123/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0669 - accuracy: 0.7942\n",
      "Epoch 124/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0660 - accuracy: 0.7934\n",
      "Epoch 125/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0602 - accuracy: 0.7964\n",
      "Epoch 126/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0594 - accuracy: 0.7962\n",
      "Epoch 127/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0556 - accuracy: 0.7964\n",
      "Epoch 128/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0514 - accuracy: 0.7981\n",
      "Epoch 129/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0512 - accuracy: 0.7986\n",
      "Epoch 130/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0472 - accuracy: 0.7990\n",
      "Epoch 131/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0432 - accuracy: 0.8004\n",
      "Epoch 132/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0403 - accuracy: 0.8015\n",
      "Epoch 133/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0385 - accuracy: 0.7998\n",
      "Epoch 134/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0354 - accuracy: 0.8022\n",
      "Epoch 135/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0317 - accuracy: 0.8016\n",
      "Epoch 136/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0300 - accuracy: 0.8043\n",
      "Epoch 137/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0276 - accuracy: 0.8032\n",
      "Epoch 138/200\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.0240 - accuracy: 0.8061\n",
      "Epoch 139/200\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.0214 - accuracy: 0.8048\n",
      "Epoch 140/200\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.0208 - accuracy: 0.8055\n",
      "Epoch 141/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.0184 - accuracy: 0.8071\n",
      "Epoch 142/200\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.0134 - accuracy: 0.8068\n",
      "Epoch 143/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0110 - accuracy: 0.8091\n",
      "Epoch 144/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0091 - accuracy: 0.8097\n",
      "Epoch 145/200\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.0081 - accuracy: 0.8081\n",
      "Epoch 146/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0061 - accuracy: 0.8094\n",
      "Epoch 147/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0023 - accuracy: 0.8120\n",
      "Epoch 148/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0011 - accuracy: 0.8105\n",
      "Epoch 149/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9977 - accuracy: 0.8115\n",
      "Epoch 150/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9938 - accuracy: 0.8127\n",
      "Epoch 151/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9920 - accuracy: 0.8149\n",
      "Epoch 152/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9902 - accuracy: 0.8125\n",
      "Epoch 153/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9886 - accuracy: 0.8141\n",
      "Epoch 154/200\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.9852 - accuracy: 0.8148\n",
      "Epoch 155/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9821 - accuracy: 0.8160\n",
      "Epoch 156/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9808 - accuracy: 0.8160\n",
      "Epoch 157/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9764 - accuracy: 0.8182\n",
      "Epoch 158/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9757 - accuracy: 0.8185\n",
      "Epoch 159/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9743 - accuracy: 0.8180\n",
      "Epoch 160/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9725 - accuracy: 0.8195\n",
      "Epoch 161/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9691 - accuracy: 0.8189\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9664 - accuracy: 0.8210\n",
      "Epoch 163/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9654 - accuracy: 0.8202\n",
      "Epoch 164/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9626 - accuracy: 0.8217\n",
      "Epoch 165/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9611 - accuracy: 0.8219\n",
      "Epoch 166/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9598 - accuracy: 0.8224\n",
      "Epoch 167/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9566 - accuracy: 0.8228\n",
      "Epoch 168/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9537 - accuracy: 0.8243\n",
      "Epoch 169/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9534 - accuracy: 0.8225\n",
      "Epoch 170/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9520 - accuracy: 0.8235\n",
      "Epoch 171/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9489 - accuracy: 0.8243\n",
      "Epoch 172/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9464 - accuracy: 0.8248\n",
      "Epoch 173/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9454 - accuracy: 0.8259\n",
      "Epoch 174/200\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.9406 - accuracy: 0.8284\n",
      "Epoch 175/200\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.9400 - accuracy: 0.8259\n",
      "Epoch 176/200\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.9385 - accuracy: 0.8278\n",
      "Epoch 177/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9376 - accuracy: 0.8270\n",
      "Epoch 178/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9356 - accuracy: 0.8283\n",
      "Epoch 179/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9322 - accuracy: 0.8285\n",
      "Epoch 180/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9312 - accuracy: 0.8312\n",
      "Epoch 181/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9284 - accuracy: 0.8295\n",
      "Epoch 182/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9261 - accuracy: 0.8314\n",
      "Epoch 183/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9255 - accuracy: 0.8313\n",
      "Epoch 184/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9233 - accuracy: 0.8319\n",
      "Epoch 185/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9217 - accuracy: 0.8311\n",
      "Epoch 186/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9198 - accuracy: 0.8322\n",
      "Epoch 187/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9170 - accuracy: 0.8345\n",
      "Epoch 188/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9169 - accuracy: 0.8327\n",
      "Epoch 189/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9125 - accuracy: 0.8346\n",
      "Epoch 190/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9129 - accuracy: 0.8352\n",
      "Epoch 191/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9101 - accuracy: 0.8352\n",
      "Epoch 192/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9078 - accuracy: 0.8365\n",
      "Epoch 193/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9068 - accuracy: 0.8361\n",
      "Epoch 194/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9056 - accuracy: 0.8355\n",
      "Epoch 195/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9034 - accuracy: 0.8357\n",
      "Epoch 196/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9007 - accuracy: 0.8381\n",
      "Epoch 197/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9005 - accuracy: 0.8376\n",
      "Epoch 198/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8972 - accuracy: 0.8390\n",
      "Epoch 199/200\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8966 - accuracy: 0.8371\n",
      "Epoch 200/200\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8954 - accuracy: 0.8393\n",
      "Accuracy in training dataset: {0} 0.8364523649215698\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.9560 - accuracy: 0.8108\n",
      "Accuracy in test dataset : {0} 0.8108333349227905\n"
     ]
    }
   ],
   "source": [
    "# changing value of learning rate to check the impact \n",
    "lr = 0.01\n",
    "Lambda = .1\n",
    "x_train = x_train.reshape(42000, 1024)\n",
    "x_test = x_test.reshape(18000, 1024)\n",
    "score, model = train_and_test_loop_withOneDropouts(200, lr, Lambda, x_train)\n",
    "print(\"Accuracy in training dataset: {0}\", score[1])\n",
    "testscore = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 2.5693 - accuracy: 0.1264\n",
      "Epoch 2/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 2.2876 - accuracy: 0.1930\n",
      "Epoch 3/120\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 2.1441 - accuracy: 0.2576\n",
      "Epoch 4/120\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.0188 - accuracy: 0.3097\n",
      "Epoch 5/120\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.9118 - accuracy: 0.3635\n",
      "Epoch 6/120\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.8125 - accuracy: 0.4045\n",
      "Epoch 7/120\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.7319 - accuracy: 0.4377\n",
      "Epoch 8/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.6590 - accuracy: 0.4705\n",
      "Epoch 9/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.5901 - accuracy: 0.4998\n",
      "Epoch 10/120\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.5286 - accuracy: 0.5257\n",
      "Epoch 11/120\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.4765 - accuracy: 0.5489\n",
      "Epoch 12/120\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.4232 - accuracy: 0.5664\n",
      "Epoch 13/120\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.3815 - accuracy: 0.5823\n",
      "Epoch 14/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.3415 - accuracy: 0.5996\n",
      "Epoch 15/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3059 - accuracy: 0.6124\n",
      "Epoch 16/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2700 - accuracy: 0.6245\n",
      "Epoch 17/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.2434 - accuracy: 0.6349\n",
      "Epoch 18/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2144 - accuracy: 0.6449\n",
      "Epoch 19/120\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.1885 - accuracy: 0.6531\n",
      "Epoch 20/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1624 - accuracy: 0.6615\n",
      "Epoch 21/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1412 - accuracy: 0.6666\n",
      "Epoch 22/120\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.1204 - accuracy: 0.6735\n",
      "Epoch 23/120\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.1046 - accuracy: 0.6803\n",
      "Epoch 24/120\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.0832 - accuracy: 0.6846\n",
      "Epoch 25/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0676 - accuracy: 0.6919\n",
      "Epoch 26/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0511 - accuracy: 0.6960\n",
      "Epoch 27/120\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.0368 - accuracy: 0.7010\n",
      "Epoch 28/120\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.0206 - accuracy: 0.7066\n",
      "Epoch 29/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0078 - accuracy: 0.7085\n",
      "Epoch 30/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9960 - accuracy: 0.7130\n",
      "Epoch 31/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9806 - accuracy: 0.7187\n",
      "Epoch 32/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9697 - accuracy: 0.7214\n",
      "Epoch 33/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9581 - accuracy: 0.7258\n",
      "Epoch 34/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9469 - accuracy: 0.7277\n",
      "Epoch 35/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9345 - accuracy: 0.7309\n",
      "Epoch 36/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9211 - accuracy: 0.7354\n",
      "Epoch 37/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9118 - accuracy: 0.7397\n",
      "Epoch 38/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9027 - accuracy: 0.7415\n",
      "Epoch 39/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8948 - accuracy: 0.7431\n",
      "Epoch 40/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8870 - accuracy: 0.7457\n",
      "Epoch 41/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8775 - accuracy: 0.7487\n",
      "Epoch 42/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8675 - accuracy: 0.7536\n",
      "Epoch 43/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8592 - accuracy: 0.7543\n",
      "Epoch 44/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8514 - accuracy: 0.7571\n",
      "Epoch 45/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8424 - accuracy: 0.7584\n",
      "Epoch 46/120\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8313 - accuracy: 0.7633\n",
      "Epoch 47/120\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8269 - accuracy: 0.7660\n",
      "Epoch 48/120\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.8191 - accuracy: 0.7674\n",
      "Epoch 49/120\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8118 - accuracy: 0.7679\n",
      "Epoch 50/120\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.8046 - accuracy: 0.7718\n",
      "Epoch 51/120\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.7973 - accuracy: 0.7746\n",
      "Epoch 52/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7879 - accuracy: 0.7746\n",
      "Epoch 53/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7869 - accuracy: 0.7766\n",
      "Epoch 54/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7757 - accuracy: 0.7804\n",
      "Epoch 55/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7716 - accuracy: 0.7804\n",
      "Epoch 56/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7637 - accuracy: 0.7843\n",
      "Epoch 57/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7591 - accuracy: 0.7860\n",
      "Epoch 58/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7516 - accuracy: 0.7889\n",
      "Epoch 59/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7483 - accuracy: 0.7880\n",
      "Epoch 60/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7420 - accuracy: 0.7906\n",
      "Epoch 61/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7348 - accuracy: 0.7923\n",
      "Epoch 62/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7336 - accuracy: 0.7924\n",
      "Epoch 63/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7265 - accuracy: 0.7947\n",
      "Epoch 64/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7179 - accuracy: 0.7975\n",
      "Epoch 65/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7139 - accuracy: 0.8002\n",
      "Epoch 66/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7119 - accuracy: 0.7981\n",
      "Epoch 67/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7077 - accuracy: 0.8011\n",
      "Epoch 68/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7042 - accuracy: 0.8021\n",
      "Epoch 69/120\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6972 - accuracy: 0.8030\n",
      "Epoch 70/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6957 - accuracy: 0.8033\n",
      "Epoch 71/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6900 - accuracy: 0.8065\n",
      "Epoch 72/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6846 - accuracy: 0.8085\n",
      "Epoch 73/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6820 - accuracy: 0.8091\n",
      "Epoch 74/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6749 - accuracy: 0.8101\n",
      "Epoch 75/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6743 - accuracy: 0.8096\n",
      "Epoch 76/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6692 - accuracy: 0.8119\n",
      "Epoch 77/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6654 - accuracy: 0.8134\n",
      "Epoch 78/120\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6681 - accuracy: 0.8128\n",
      "Epoch 79/120\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.6598 - accuracy: 0.8145\n",
      "Epoch 80/120\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6550 - accuracy: 0.8176\n",
      "Epoch 81/120\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6534 - accuracy: 0.8174\n",
      "Epoch 82/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6471 - accuracy: 0.8197\n",
      "Epoch 83/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6519 - accuracy: 0.8152\n",
      "Epoch 84/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6389 - accuracy: 0.8213\n",
      "Epoch 85/120\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6325 - accuracy: 0.8227\n",
      "Epoch 86/120\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6300 - accuracy: 0.8248\n",
      "Epoch 87/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6342 - accuracy: 0.8232\n",
      "Epoch 88/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6303 - accuracy: 0.8248\n",
      "Epoch 89/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6326 - accuracy: 0.8222\n",
      "Epoch 90/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6219 - accuracy: 0.8260\n",
      "Epoch 91/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6179 - accuracy: 0.8284\n",
      "Epoch 92/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6241 - accuracy: 0.8258\n",
      "Epoch 93/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6120 - accuracy: 0.8308\n",
      "Epoch 94/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6181 - accuracy: 0.8267\n",
      "Epoch 95/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6061 - accuracy: 0.8316\n",
      "Epoch 96/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6021 - accuracy: 0.8318\n",
      "Epoch 97/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6053 - accuracy: 0.8310\n",
      "Epoch 98/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5979 - accuracy: 0.8334\n",
      "Epoch 99/120\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6025 - accuracy: 0.8307\n",
      "Epoch 100/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.5957 - accuracy: 0.8344\n",
      "Epoch 101/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5921 - accuracy: 0.8361\n",
      "Epoch 102/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5898 - accuracy: 0.8375\n",
      "Epoch 103/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5876 - accuracy: 0.8378\n",
      "Epoch 104/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5825 - accuracy: 0.8372\n",
      "Epoch 105/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5860 - accuracy: 0.8374\n",
      "Epoch 106/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5852 - accuracy: 0.8370\n",
      "Epoch 107/120\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.5883 - accuracy: 0.8359\n",
      "Epoch 108/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5725 - accuracy: 0.8428\n",
      "Epoch 109/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5756 - accuracy: 0.8415\n",
      "Epoch 110/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5752 - accuracy: 0.8407\n",
      "Epoch 111/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5753 - accuracy: 0.8404\n",
      "Epoch 112/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5655 - accuracy: 0.8445\n",
      "Epoch 113/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5697 - accuracy: 0.8427\n",
      "Epoch 114/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5659 - accuracy: 0.8421\n",
      "Epoch 115/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5631 - accuracy: 0.8440\n",
      "Epoch 116/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5647 - accuracy: 0.8433\n",
      "Epoch 117/120\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5555 - accuracy: 0.8466\n",
      "Epoch 118/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5520 - accuracy: 0.8483\n",
      "Epoch 119/120\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5581 - accuracy: 0.8468\n",
      "Epoch 120/120\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5458 - accuracy: 0.8496\n",
      "Accuracy in training dataset: {0} 0.7939761877059937\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.8692 - accuracy: 0.7518\n",
      "Accuracy in test dataset : {0} 0.7518333196640015\n"
     ]
    }
   ],
   "source": [
    "# changing value of learning rate to check the impact \n",
    "lr = 0.01\n",
    "Lambda = .0015\n",
    "x_train = x_train.reshape(42000, 1024)\n",
    "x_test = x_test.reshape(18000, 1024)\n",
    "score, model = train_and_test_loop_withOneDropouts(120, lr, Lambda, x_train)\n",
    "print(\"Accuracy in training dataset: {0}\", score[1])\n",
    "testscore = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "### adding 2 dropouts to avoid overfitting \n",
    "\n",
    "def train_and_test_loop_withDropouts(iterations,lr, Lambda, x_train, verb=True):\n",
    "\n",
    "     #hyperparameters\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "      \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(1024,)))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu'))  \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(hidden_nodes))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=learning_rate)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer= sgd , metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(x_train, y_train, verbose=0)\n",
    "    \n",
    "    # Fit the model   \n",
    "    return score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.6397 - accuracy: 0.1129\n",
      "Epoch 2/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.4265 - accuracy: 0.1444\n",
      "Epoch 3/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.3271 - accuracy: 0.1772\n",
      "Epoch 4/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.2340 - accuracy: 0.2144\n",
      "Epoch 5/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.1539 - accuracy: 0.2460\n",
      "Epoch 6/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.0785 - accuracy: 0.2814\n",
      "Epoch 7/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.0064 - accuracy: 0.3129\n",
      "Epoch 8/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.9353 - accuracy: 0.3421\n",
      "Epoch 9/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.8711 - accuracy: 0.3701\n",
      "Epoch 10/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.8115 - accuracy: 0.3926\n",
      "Epoch 11/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.7573 - accuracy: 0.4187\n",
      "Epoch 12/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.7103 - accuracy: 0.4386\n",
      "Epoch 13/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.6626 - accuracy: 0.4579\n",
      "Epoch 14/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.6205 - accuracy: 0.4762\n",
      "Epoch 15/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.5830 - accuracy: 0.4945\n",
      "Epoch 16/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.5421 - accuracy: 0.5079\n",
      "Epoch 17/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.5105 - accuracy: 0.5196\n",
      "Epoch 18/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.4810 - accuracy: 0.5354\n",
      "Epoch 19/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.4481 - accuracy: 0.5464 0s - loss: 1\n",
      "Epoch 20/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.4213 - accuracy: 0.5524\n",
      "Epoch 21/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.3962 - accuracy: 0.5660\n",
      "Epoch 22/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.3719 - accuracy: 0.5771\n",
      "Epoch 23/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.3476 - accuracy: 0.5850\n",
      "Epoch 24/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.3306 - accuracy: 0.5899\n",
      "Epoch 25/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.3119 - accuracy: 0.5974\n",
      "Epoch 26/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.2954 - accuracy: 0.6025 0s - loss: 1\n",
      "Epoch 27/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.2711 - accuracy: 0.6134 0s - loss: 1.2725 - accura\n",
      "Epoch 28/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.2634 - accuracy: 0.6139 1s -\n",
      "Epoch 29/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.2422 - accuracy: 0.6213\n",
      "Epoch 30/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.2282 - accuracy: 0.6288\n",
      "Epoch 31/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.2117 - accuracy: 0.6344\n",
      "Epoch 32/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.1958 - accuracy: 0.6388\n",
      "Epoch 33/150\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.1870 - accuracy: 0.6439\n",
      "Epoch 34/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.1780 - accuracy: 0.6446\n",
      "Epoch 35/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.1651 - accuracy: 0.6499\n",
      "Epoch 36/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.1514 - accuracy: 0.6555\n",
      "Epoch 37/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.1408 - accuracy: 0.6572\n",
      "Epoch 38/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.1353 - accuracy: 0.6599\n",
      "Epoch 39/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.1198 - accuracy: 0.6680 0s - loss: 1.122\n",
      "Epoch 40/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.1114 - accuracy: 0.6695\n",
      "Epoch 41/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.1024 - accuracy: 0.6726\n",
      "Epoch 42/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.0969 - accuracy: 0.6725\n",
      "Epoch 43/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0818 - accuracy: 0.6774\n",
      "Epoch 44/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0764 - accuracy: 0.6780\n",
      "Epoch 45/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.0655 - accuracy: 0.6825\n",
      "Epoch 46/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0627 - accuracy: 0.6825\n",
      "Epoch 47/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0509 - accuracy: 0.6881\n",
      "Epoch 48/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0426 - accuracy: 0.6900\n",
      "Epoch 49/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.0366 - accuracy: 0.6907 0s - loss: 1.0394 - accuracy\n",
      "Epoch 50/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0289 - accuracy: 0.6927\n",
      "Epoch 51/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0220 - accuracy: 0.6990\n",
      "Epoch 52/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0184 - accuracy: 0.6973\n",
      "Epoch 53/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0068 - accuracy: 0.7045 0s - loss: 1.0107 \n",
      "Epoch 54/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0023 - accuracy: 0.7033\n",
      "Epoch 55/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.9950 - accuracy: 0.7080\n",
      "Epoch 56/150\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.9883 - accuracy: 0.7091\n",
      "Epoch 57/150\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.9834 - accuracy: 0.7101\n",
      "Epoch 58/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.9756 - accuracy: 0.7141\n",
      "Epoch 59/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.9726 - accuracy: 0.7138\n",
      "Epoch 60/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9638 - accuracy: 0.7151\n",
      "Epoch 61/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9566 - accuracy: 0.7171\n",
      "Epoch 62/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.9532 - accuracy: 0.7198 0s - loss: 0.9524 - accuracy\n",
      "Epoch 63/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.9499 - accuracy: 0.7228\n",
      "Epoch 64/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.9421 - accuracy: 0.7237\n",
      "Epoch 65/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9439 - accuracy: 0.7220\n",
      "Epoch 66/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.9310 - accuracy: 0.7257\n",
      "Epoch 67/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9303 - accuracy: 0.7270\n",
      "Epoch 68/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9255 - accuracy: 0.7280 \n",
      "Epoch 69/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9174 - accuracy: 0.7331\n",
      "Epoch 70/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9105 - accuracy: 0.7328\n",
      "Epoch 71/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9093 - accuracy: 0.7322\n",
      "Epoch 72/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9077 - accuracy: 0.7339\n",
      "Epoch 73/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.9050 - accuracy: 0.7360\n",
      "Epoch 74/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8979 - accuracy: 0.7384\n",
      "Epoch 75/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8926 - accuracy: 0.7384\n",
      "Epoch 76/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8875 - accuracy: 0.7417\n",
      "Epoch 77/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8877 - accuracy: 0.7404\n",
      "Epoch 78/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8794 - accuracy: 0.7442\n",
      "Epoch 79/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8802 - accuracy: 0.7418\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8718 - accuracy: 0.7448\n",
      "Epoch 81/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8666 - accuracy: 0.7455\n",
      "Epoch 82/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.8615 - accuracy: 0.7490\n",
      "Epoch 83/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.8641 - accuracy: 0.7459\n",
      "Epoch 84/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.8584 - accuracy: 0.7509\n",
      "Epoch 85/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8520 - accuracy: 0.7534\n",
      "Epoch 86/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.8507 - accuracy: 0.7521\n",
      "Epoch 87/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8488 - accuracy: 0.7525\n",
      "Epoch 88/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8419 - accuracy: 0.7551\n",
      "Epoch 89/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.8407 - accuracy: 0.7535\n",
      "Epoch 90/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8357 - accuracy: 0.7577\n",
      "Epoch 91/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.8323 - accuracy: 0.7565\n",
      "Epoch 92/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.8297 - accuracy: 0.7599\n",
      "Epoch 93/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8293 - accuracy: 0.7599\n",
      "Epoch 94/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8227 - accuracy: 0.7605\n",
      "Epoch 95/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.8173 - accuracy: 0.7610\n",
      "Epoch 96/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8152 - accuracy: 0.7609\n",
      "Epoch 97/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8170 - accuracy: 0.7621\n",
      "Epoch 98/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8117 - accuracy: 0.7634\n",
      "Epoch 99/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8102 - accuracy: 0.7656\n",
      "Epoch 100/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8030 - accuracy: 0.7681\n",
      "Epoch 101/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7976 - accuracy: 0.7707\n",
      "Epoch 102/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8010 - accuracy: 0.7698\n",
      "Epoch 103/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7907 - accuracy: 0.7702\n",
      "Epoch 104/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7899 - accuracy: 0.7707\n",
      "Epoch 105/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7910 - accuracy: 0.7705\n",
      "Epoch 106/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7885 - accuracy: 0.7712\n",
      "Epoch 107/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7842 - accuracy: 0.7737\n",
      "Epoch 108/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7824 - accuracy: 0.7744\n",
      "Epoch 109/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7761 - accuracy: 0.7741\n",
      "Epoch 110/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7755 - accuracy: 0.7759\n",
      "Epoch 111/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7721 - accuracy: 0.7782\n",
      "Epoch 112/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7720 - accuracy: 0.7779\n",
      "Epoch 113/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7701 - accuracy: 0.7782\n",
      "Epoch 114/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7673 - accuracy: 0.7797\n",
      "Epoch 115/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7621 - accuracy: 0.7801\n",
      "Epoch 116/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.7660 - accuracy: 0.7771\n",
      "Epoch 117/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.7597 - accuracy: 0.7801\n",
      "Epoch 118/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.7574 - accuracy: 0.7813\n",
      "Epoch 119/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7512 - accuracy: 0.7819\n",
      "Epoch 120/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7513 - accuracy: 0.7820\n",
      "Epoch 121/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7514 - accuracy: 0.7823\n",
      "Epoch 122/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7496 - accuracy: 0.7835\n",
      "Epoch 123/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7418 - accuracy: 0.7867\n",
      "Epoch 124/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7422 - accuracy: 0.7858\n",
      "Epoch 125/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7463 - accuracy: 0.7846\n",
      "Epoch 126/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7357 - accuracy: 0.7874\n",
      "Epoch 127/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7427 - accuracy: 0.7837\n",
      "Epoch 128/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7390 - accuracy: 0.7856\n",
      "Epoch 129/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7349 - accuracy: 0.7883\n",
      "Epoch 130/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7315 - accuracy: 0.7892\n",
      "Epoch 131/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7288 - accuracy: 0.7913\n",
      "Epoch 132/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7260 - accuracy: 0.7914\n",
      "Epoch 133/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7233 - accuracy: 0.7910\n",
      "Epoch 134/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7237 - accuracy: 0.7894\n",
      "Epoch 135/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7187 - accuracy: 0.7927\n",
      "Epoch 136/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7197 - accuracy: 0.7923\n",
      "Epoch 137/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7185 - accuracy: 0.7935\n",
      "Epoch 138/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7173 - accuracy: 0.7928\n",
      "Epoch 139/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7120 - accuracy: 0.7962\n",
      "Epoch 140/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7065 - accuracy: 0.7979\n",
      "Epoch 141/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7099 - accuracy: 0.7949\n",
      "Epoch 142/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7077 - accuracy: 0.7975\n",
      "Epoch 143/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7048 - accuracy: 0.7973\n",
      "Epoch 144/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6992 - accuracy: 0.7986\n",
      "Epoch 145/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7012 - accuracy: 0.7972\n",
      "Epoch 146/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6977 - accuracy: 0.7990\n",
      "Epoch 147/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7020 - accuracy: 0.7963\n",
      "Epoch 148/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6959 - accuracy: 0.8012\n",
      "Epoch 149/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6965 - accuracy: 0.7975\n",
      "Epoch 150/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6963 - accuracy: 0.8000\n",
      "Accuracy in training dataset: {0} 0.8546904921531677\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.6433 - accuracy: 0.8264\n",
      "Accuracy in test dataset : {0} 0.8264444470405579\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = 0.01\n",
    "Lambda = .0015\n",
    "x_train = x_train.reshape(42000, 1024)\n",
    "x_test = x_test.reshape(18000, 1024)\n",
    "score, model = train_and_test_loop_withDropouts(150, lr, Lambda, x_train)\n",
    "print(\"Accuracy in training dataset: {0}\", score[1])\n",
    "testscore = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We got so far the best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.6468 - accuracy: 0.1061\n",
      "Epoch 2/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.5334 - accuracy: 0.1188\n",
      "Epoch 3/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.4628 - accuracy: 0.1313\n",
      "Epoch 4/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.4119 - accuracy: 0.1461\n",
      "Epoch 5/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.3679 - accuracy: 0.1598\n",
      "Epoch 6/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.3246 - accuracy: 0.1739\n",
      "Epoch 7/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.2918 - accuracy: 0.1840\n",
      "Epoch 8/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.2585 - accuracy: 0.1963\n",
      "Epoch 9/150\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.2296 - accuracy: 0.2060\n",
      "Epoch 10/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.1968 - accuracy: 0.2176\n",
      "Epoch 11/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.1707 - accuracy: 0.2298\n",
      "Epoch 12/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.1464 - accuracy: 0.2391\n",
      "Epoch 13/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.1211 - accuracy: 0.2480\n",
      "Epoch 14/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.0935 - accuracy: 0.2550\n",
      "Epoch 15/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.0696 - accuracy: 0.2677\n",
      "Epoch 16/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.0476 - accuracy: 0.2731\n",
      "Epoch 17/150\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.0287 - accuracy: 0.2804\n",
      "Epoch 18/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.0097 - accuracy: 0.2882\n",
      "Epoch 19/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.9955 - accuracy: 0.2928\n",
      "Epoch 20/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.9792 - accuracy: 0.2978\n",
      "Epoch 21/150\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.9599 - accuracy: 0.3070\n",
      "Epoch 22/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.9429 - accuracy: 0.3128\n",
      "Epoch 23/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.9304 - accuracy: 0.3193\n",
      "Epoch 24/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.9145 - accuracy: 0.3212\n",
      "Epoch 25/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.9032 - accuracy: 0.3285\n",
      "Epoch 26/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.8869 - accuracy: 0.3320\n",
      "Epoch 27/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.8812 - accuracy: 0.3380\n",
      "Epoch 28/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.8621 - accuracy: 0.3429\n",
      "Epoch 29/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.8567 - accuracy: 0.3465\n",
      "Epoch 30/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.8460 - accuracy: 0.3472\n",
      "Epoch 31/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.8367 - accuracy: 0.3515\n",
      "Epoch 32/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.8254 - accuracy: 0.3585\n",
      "Epoch 33/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.8191 - accuracy: 0.3610\n",
      "Epoch 34/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.8094 - accuracy: 0.3637\n",
      "Epoch 35/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.7967 - accuracy: 0.3663\n",
      "Epoch 36/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.7912 - accuracy: 0.3698\n",
      "Epoch 37/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.7837 - accuracy: 0.3714\n",
      "Epoch 38/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.7749 - accuracy: 0.3751\n",
      "Epoch 39/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.7670 - accuracy: 0.3789\n",
      "Epoch 40/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.7625 - accuracy: 0.3809\n",
      "Epoch 41/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.7567 - accuracy: 0.3812 0s - loss: 1.7\n",
      "Epoch 42/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.7491 - accuracy: 0.3843\n",
      "Epoch 43/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.7401 - accuracy: 0.3884\n",
      "Epoch 44/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.7346 - accuracy: 0.3912\n",
      "Epoch 45/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.7300 - accuracy: 0.3929\n",
      "Epoch 46/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.7239 - accuracy: 0.3956\n",
      "Epoch 47/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.7172 - accuracy: 0.3949\n",
      "Epoch 48/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.7124 - accuracy: 0.4007\n",
      "Epoch 49/150\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.7075 - accuracy: 0.4009\n",
      "Epoch 50/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.7079 - accuracy: 0.3992\n",
      "Epoch 51/150\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.6982 - accuracy: 0.4049\n",
      "Epoch 52/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.6967 - accuracy: 0.4037\n",
      "Epoch 53/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.6856 - accuracy: 0.4092\n",
      "Epoch 54/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.6844 - accuracy: 0.4101\n",
      "Epoch 55/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.6830 - accuracy: 0.4110\n",
      "Epoch 56/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.6755 - accuracy: 0.4136\n",
      "Epoch 57/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6756 - accuracy: 0.4120\n",
      "Epoch 58/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6675 - accuracy: 0.4147\n",
      "Epoch 59/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6682 - accuracy: 0.4140\n",
      "Epoch 60/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.6581 - accuracy: 0.4215\n",
      "Epoch 61/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6549 - accuracy: 0.4223\n",
      "Epoch 62/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6508 - accuracy: 0.4218\n",
      "Epoch 63/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6511 - accuracy: 0.4224\n",
      "Epoch 64/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6442 - accuracy: 0.4218\n",
      "Epoch 65/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6383 - accuracy: 0.4298\n",
      "Epoch 66/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6393 - accuracy: 0.4276\n",
      "Epoch 67/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6309 - accuracy: 0.4298\n",
      "Epoch 68/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6303 - accuracy: 0.4252\n",
      "Epoch 69/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6261 - accuracy: 0.4323\n",
      "Epoch 70/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.6225 - accuracy: 0.4338\n",
      "Epoch 71/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.6211 - accuracy: 0.4331\n",
      "Epoch 72/150\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.6190 - accuracy: 0.4350\n",
      "Epoch 73/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.6165 - accuracy: 0.4362 0s - loss: 1.6225 - ac\n",
      "Epoch 74/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.6095 - accuracy: 0.4379\n",
      "Epoch 75/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.6064 - accuracy: 0.4386\n",
      "Epoch 76/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6090 - accuracy: 0.4377\n",
      "Epoch 77/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6051 - accuracy: 0.4381\n",
      "Epoch 78/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6003 - accuracy: 0.4427\n",
      "Epoch 79/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5954 - accuracy: 0.4420\n",
      "Epoch 80/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5948 - accuracy: 0.4421\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5905 - accuracy: 0.4441\n",
      "Epoch 82/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.5857 - accuracy: 0.4474\n",
      "Epoch 83/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.5878 - accuracy: 0.4454\n",
      "Epoch 84/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.5828 - accuracy: 0.4467\n",
      "Epoch 85/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5830 - accuracy: 0.4472\n",
      "Epoch 86/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.5800 - accuracy: 0.4478\n",
      "Epoch 87/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.5767 - accuracy: 0.4496\n",
      "Epoch 88/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.5745 - accuracy: 0.4510\n",
      "Epoch 89/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.5719 - accuracy: 0.4495\n",
      "Epoch 90/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5651 - accuracy: 0.4552\n",
      "Epoch 91/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.5696 - accuracy: 0.4515\n",
      "Epoch 92/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.5620 - accuracy: 0.4551\n",
      "Epoch 93/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.5608 - accuracy: 0.4543\n",
      "Epoch 94/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5631 - accuracy: 0.4535\n",
      "Epoch 95/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5590 - accuracy: 0.4558\n",
      "Epoch 96/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.5565 - accuracy: 0.4571\n",
      "Epoch 97/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.5572 - accuracy: 0.4562\n",
      "Epoch 98/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5556 - accuracy: 0.4558\n",
      "Epoch 99/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.5513 - accuracy: 0.4613\n",
      "Epoch 100/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.5505 - accuracy: 0.4589\n",
      "Epoch 101/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5475 - accuracy: 0.4610\n",
      "Epoch 102/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5442 - accuracy: 0.4636\n",
      "Epoch 103/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5435 - accuracy: 0.4591\n",
      "Epoch 104/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5379 - accuracy: 0.4643\n",
      "Epoch 105/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.5355 - accuracy: 0.4633\n",
      "Epoch 106/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5328 - accuracy: 0.4659\n",
      "Epoch 107/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5341 - accuracy: 0.4645\n",
      "Epoch 108/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.5347 - accuracy: 0.4657\n",
      "Epoch 109/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.5289 - accuracy: 0.4677\n",
      "Epoch 110/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5292 - accuracy: 0.4651\n",
      "Epoch 111/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5249 - accuracy: 0.4672\n",
      "Epoch 112/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5231 - accuracy: 0.4677\n",
      "Epoch 113/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5217 - accuracy: 0.4692 0s - loss: 1.5214 - accuracy\n",
      "Epoch 114/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.5170 - accuracy: 0.4696\n",
      "Epoch 115/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5171 - accuracy: 0.4705\n",
      "Epoch 116/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5193 - accuracy: 0.4690\n",
      "Epoch 117/150\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.5138 - accuracy: 0.4744\n",
      "Epoch 118/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.5120 - accuracy: 0.4729\n",
      "Epoch 119/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.5115 - accuracy: 0.4720\n",
      "Epoch 120/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5056 - accuracy: 0.4735\n",
      "Epoch 121/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5066 - accuracy: 0.4739\n",
      "Epoch 122/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5029 - accuracy: 0.4766\n",
      "Epoch 123/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5056 - accuracy: 0.4762\n",
      "Epoch 124/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5005 - accuracy: 0.4772\n",
      "Epoch 125/150\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.5003 - accuracy: 0.4804\n",
      "Epoch 126/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5025 - accuracy: 0.4758\n",
      "Epoch 127/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4975 - accuracy: 0.4773\n",
      "Epoch 128/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.4915 - accuracy: 0.4801\n",
      "Epoch 129/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.4954 - accuracy: 0.4769\n",
      "Epoch 130/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4898 - accuracy: 0.4796\n",
      "Epoch 131/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4906 - accuracy: 0.4795\n",
      "Epoch 132/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4867 - accuracy: 0.4820\n",
      "Epoch 133/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4869 - accuracy: 0.4809\n",
      "Epoch 134/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4836 - accuracy: 0.4836\n",
      "Epoch 135/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.4842 - accuracy: 0.4830\n",
      "Epoch 136/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.4831 - accuracy: 0.4846\n",
      "Epoch 137/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.4851 - accuracy: 0.4806\n",
      "Epoch 138/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4820 - accuracy: 0.4819\n",
      "Epoch 139/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4771 - accuracy: 0.4869\n",
      "Epoch 140/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.4758 - accuracy: 0.4852\n",
      "Epoch 141/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.4739 - accuracy: 0.4838\n",
      "Epoch 142/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.4683 - accuracy: 0.4906\n",
      "Epoch 143/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4702 - accuracy: 0.4877\n",
      "Epoch 144/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4708 - accuracy: 0.4868\n",
      "Epoch 145/150\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.4710 - accuracy: 0.4867\n",
      "Epoch 146/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.4692 - accuracy: 0.4914 0s - loss: 1.4695 - accuracy: 0.49\n",
      "Epoch 147/150\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.4650 - accuracy: 0.4912\n",
      "Epoch 148/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4619 - accuracy: 0.4919\n",
      "Epoch 149/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4620 - accuracy: 0.4910\n",
      "Epoch 150/150\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4649 - accuracy: 0.4909\n",
      "Accuracy in training dataset: {0} 0.548285722732544\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 1.4474 - accuracy: 0.5019\n",
      "Accuracy in test dataset : {0} 0.5018888711929321\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "Lambda = .0015\n",
    "X_train_normalize, x_test_normalize, x_val_normalize = Normalize(x_train, x_test, x_val)\n",
    "score, model = train_and_test_loop_withDropouts(150, lr, Lambda, X_train_normalize)\n",
    "print(\"Accuracy in training dataset: {0}\", score[1])\n",
    "testscore = model.evaluate(x_test_normalize, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 2.3245 - accuracy: 0.1993\n",
      "Epoch 2/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.8396 - accuracy: 0.3863\n",
      "Epoch 3/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.5590 - accuracy: 0.5018\n",
      "Epoch 4/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.3977 - accuracy: 0.5635\n",
      "Epoch 5/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.2897 - accuracy: 0.6015\n",
      "Epoch 6/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.2153 - accuracy: 0.6266\n",
      "Epoch 7/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.1621 - accuracy: 0.6464\n",
      "Epoch 8/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.1088 - accuracy: 0.6644\n",
      "Epoch 9/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0898 - accuracy: 0.6687\n",
      "Epoch 10/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.0412 - accuracy: 0.6862\n",
      "Epoch 11/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.0181 - accuracy: 0.6956\n",
      "Epoch 12/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9919 - accuracy: 0.7025\n",
      "Epoch 13/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9773 - accuracy: 0.7078\n",
      "Epoch 14/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9599 - accuracy: 0.7119\n",
      "Epoch 15/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9236 - accuracy: 0.7286\n",
      "Epoch 16/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.9066 - accuracy: 0.7316\n",
      "Epoch 17/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8985 - accuracy: 0.7319\n",
      "Epoch 18/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8848 - accuracy: 0.7372\n",
      "Epoch 19/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8641 - accuracy: 0.7435 0s - loss:\n",
      "Epoch 20/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8512 - accuracy: 0.7488\n",
      "Epoch 21/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8525 - accuracy: 0.7499\n",
      "Epoch 22/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8329 - accuracy: 0.7553\n",
      "Epoch 23/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8154 - accuracy: 0.7614\n",
      "Epoch 24/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7979 - accuracy: 0.7678\n",
      "Epoch 25/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8043 - accuracy: 0.7653\n",
      "Epoch 26/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7934 - accuracy: 0.7661\n",
      "Epoch 27/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7826 - accuracy: 0.7693\n",
      "Epoch 28/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7667 - accuracy: 0.7756\n",
      "Epoch 29/180\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7706 - accuracy: 0.7741\n",
      "Epoch 30/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7542 - accuracy: 0.7802\n",
      "Epoch 31/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7440 - accuracy: 0.7830 1s\n",
      "Epoch 32/180\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.7509 - accuracy: 0.7795 0s - loss: 0.7547 - accuracy: \n",
      "Epoch 33/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7365 - accuracy: 0.7855\n",
      "Epoch 34/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7233 - accuracy: 0.7878\n",
      "Epoch 35/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7172 - accuracy: 0.7921\n",
      "Epoch 36/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7093 - accuracy: 0.7934\n",
      "Epoch 37/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7051 - accuracy: 0.7958\n",
      "Epoch 38/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6999 - accuracy: 0.7979\n",
      "Epoch 39/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7095 - accuracy: 0.7932\n",
      "Epoch 40/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6992 - accuracy: 0.7965\n",
      "Epoch 41/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6875 - accuracy: 0.8005\n",
      "Epoch 42/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6867 - accuracy: 0.8001\n",
      "Epoch 43/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6815 - accuracy: 0.8030\n",
      "Epoch 44/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6785 - accuracy: 0.8025\n",
      "Epoch 45/180\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6711 - accuracy: 0.8051\n",
      "Epoch 46/180\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6715 - accuracy: 0.8041\n",
      "Epoch 47/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6499 - accuracy: 0.8128 0s - loss: 0.6537 - \n",
      "Epoch 48/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6550 - accuracy: 0.8114\n",
      "Epoch 49/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6464 - accuracy: 0.8132\n",
      "Epoch 50/180\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6460 - accuracy: 0.8158\n",
      "Epoch 51/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6421 - accuracy: 0.8160\n",
      "Epoch 52/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6284 - accuracy: 0.8198\n",
      "Epoch 53/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6350 - accuracy: 0.8180\n",
      "Epoch 54/180\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6168 - accuracy: 0.8223\n",
      "Epoch 55/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6298 - accuracy: 0.8178\n",
      "Epoch 56/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6167 - accuracy: 0.8241\n",
      "Epoch 57/180\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6168 - accuracy: 0.8226\n",
      "Epoch 58/180\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6118 - accuracy: 0.8232\n",
      "Epoch 59/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6073 - accuracy: 0.8255\n",
      "Epoch 60/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5931 - accuracy: 0.8304\n",
      "Epoch 61/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6211 - accuracy: 0.8197\n",
      "Epoch 62/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5956 - accuracy: 0.8303\n",
      "Epoch 63/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6229 - accuracy: 0.8197\n",
      "Epoch 64/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5918 - accuracy: 0.8318\n",
      "Epoch 65/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5835 - accuracy: 0.8320 0s - loss: 0.5773 - ac\n",
      "Epoch 66/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5801 - accuracy: 0.8348\n",
      "Epoch 67/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5712 - accuracy: 0.8364\n",
      "Epoch 68/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5935 - accuracy: 0.8287\n",
      "Epoch 69/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5780 - accuracy: 0.8361\n",
      "Epoch 70/180\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5953 - accuracy: 0.8289\n",
      "Epoch 71/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5675 - accuracy: 0.8376\n",
      "Epoch 72/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5777 - accuracy: 0.8340\n",
      "Epoch 73/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5654 - accuracy: 0.8386\n",
      "Epoch 74/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5793 - accuracy: 0.8350\n",
      "Epoch 75/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5714 - accuracy: 0.8351\n",
      "Epoch 76/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5531 - accuracy: 0.8423\n",
      "Epoch 77/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5653 - accuracy: 0.8375\n",
      "Epoch 78/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5481 - accuracy: 0.8439\n",
      "Epoch 79/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5675 - accuracy: 0.8349\n",
      "Epoch 80/180\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5564 - accuracy: 0.8421\n",
      "Epoch 81/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5456 - accuracy: 0.8441\n",
      "Epoch 82/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5283 - accuracy: 0.8511\n",
      "Epoch 83/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5667 - accuracy: 0.8387\n",
      "Epoch 84/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5275 - accuracy: 0.8502\n",
      "Epoch 85/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5305 - accuracy: 0.8503\n",
      "Epoch 86/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5553 - accuracy: 0.8410\n",
      "Epoch 87/180\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5269 - accuracy: 0.8501\n",
      "Epoch 88/180\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5392 - accuracy: 0.8467\n",
      "Epoch 89/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5507 - accuracy: 0.8431\n",
      "Epoch 90/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5265 - accuracy: 0.8500\n",
      "Epoch 91/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5297 - accuracy: 0.8473\n",
      "Epoch 92/180\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5210 - accuracy: 0.8508\n",
      "Epoch 93/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5336 - accuracy: 0.8463\n",
      "Epoch 94/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5079 - accuracy: 0.8559\n",
      "Epoch 95/180\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5077 - accuracy: 0.8569\n",
      "Epoch 96/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5085 - accuracy: 0.8553\n",
      "Epoch 97/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5119 - accuracy: 0.8534\n",
      "Epoch 98/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5059 - accuracy: 0.8561\n",
      "Epoch 99/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5420 - accuracy: 0.8438\n",
      "Epoch 100/180\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.4993 - accuracy: 0.8577\n",
      "Epoch 101/180\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5055 - accuracy: 0.8557\n",
      "Epoch 102/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5093 - accuracy: 0.8554\n",
      "Epoch 103/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5064 - accuracy: 0.8544\n",
      "Epoch 104/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5159 - accuracy: 0.8521\n",
      "Epoch 105/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4967 - accuracy: 0.8566\n",
      "Epoch 106/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5022 - accuracy: 0.8567\n",
      "Epoch 107/180\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5006 - accuracy: 0.8559\n",
      "Epoch 108/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5050 - accuracy: 0.8563\n",
      "Epoch 109/180\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5130 - accuracy: 0.8540\n",
      "Epoch 110/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4883 - accuracy: 0.8592\n",
      "Epoch 111/180\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.4959 - accuracy: 0.8569\n",
      "Epoch 112/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4907 - accuracy: 0.8607\n",
      "Epoch 113/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4841 - accuracy: 0.8624\n",
      "Epoch 114/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4873 - accuracy: 0.8616\n",
      "Epoch 115/180\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.4878 - accuracy: 0.8621\n",
      "Epoch 116/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4867 - accuracy: 0.8628\n",
      "Epoch 117/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4749 - accuracy: 0.8650\n",
      "Epoch 118/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4847 - accuracy: 0.8620\n",
      "Epoch 119/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4690 - accuracy: 0.8691\n",
      "Epoch 120/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4948 - accuracy: 0.8586\n",
      "Epoch 121/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4817 - accuracy: 0.8634\n",
      "Epoch 122/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4794 - accuracy: 0.8631\n",
      "Epoch 123/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4666 - accuracy: 0.8663\n",
      "Epoch 124/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4746 - accuracy: 0.8660\n",
      "Epoch 125/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4766 - accuracy: 0.8644\n",
      "Epoch 126/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4625 - accuracy: 0.8685\n",
      "Epoch 127/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4770 - accuracy: 0.8644\n",
      "Epoch 128/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4846 - accuracy: 0.8621\n",
      "Epoch 129/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4772 - accuracy: 0.8641\n",
      "Epoch 130/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4470 - accuracy: 0.8738\n",
      "Epoch 131/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4519 - accuracy: 0.8725\n",
      "Epoch 132/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4550 - accuracy: 0.8700\n",
      "Epoch 133/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4565 - accuracy: 0.8717\n",
      "Epoch 134/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4516 - accuracy: 0.8731\n",
      "Epoch 135/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4888 - accuracy: 0.8623\n",
      "Epoch 136/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4505 - accuracy: 0.8724\n",
      "Epoch 137/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4485 - accuracy: 0.8749\n",
      "Epoch 138/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4577 - accuracy: 0.8693\n",
      "Epoch 139/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4452 - accuracy: 0.8765\n",
      "Epoch 140/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4589 - accuracy: 0.8696\n",
      "Epoch 141/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4478 - accuracy: 0.8746\n",
      "Epoch 142/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4370 - accuracy: 0.8765\n",
      "Epoch 143/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4411 - accuracy: 0.8739\n",
      "Epoch 144/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4616 - accuracy: 0.8688\n",
      "Epoch 145/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4528 - accuracy: 0.8717\n",
      "Epoch 146/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4472 - accuracy: 0.8749\n",
      "Epoch 147/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4498 - accuracy: 0.8719\n",
      "Epoch 148/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4405 - accuracy: 0.8771\n",
      "Epoch 149/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4364 - accuracy: 0.8769\n",
      "Epoch 150/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4482 - accuracy: 0.8729\n",
      "Epoch 151/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4399 - accuracy: 0.8763\n",
      "Epoch 152/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4265 - accuracy: 0.8808\n",
      "Epoch 153/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4471 - accuracy: 0.8718\n",
      "Epoch 154/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4256 - accuracy: 0.8810\n",
      "Epoch 155/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4318 - accuracy: 0.8785\n",
      "Epoch 156/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4364 - accuracy: 0.8770\n",
      "Epoch 157/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4265 - accuracy: 0.8813\n",
      "Epoch 158/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4259 - accuracy: 0.8817\n",
      "Epoch 159/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4269 - accuracy: 0.8807\n",
      "Epoch 160/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4183 - accuracy: 0.8833\n",
      "Epoch 161/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4366 - accuracy: 0.8759\n",
      "Epoch 162/180\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4330 - accuracy: 0.8773\n",
      "Epoch 163/180\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.4149 - accuracy: 0.8841\n",
      "Epoch 164/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4170 - accuracy: 0.8823\n",
      "Epoch 165/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4508 - accuracy: 0.8732\n",
      "Epoch 166/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4301 - accuracy: 0.8778\n",
      "Epoch 167/180\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.4187 - accuracy: 0.8832\n",
      "Epoch 168/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4254 - accuracy: 0.8802\n",
      "Epoch 169/180\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.4179 - accuracy: 0.8825\n",
      "Epoch 170/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4264 - accuracy: 0.8798\n",
      "Epoch 171/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4158 - accuracy: 0.8818\n",
      "Epoch 172/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4146 - accuracy: 0.8835\n",
      "Epoch 173/180\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.4436 - accuracy: 0.8750\n",
      "Epoch 174/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4111 - accuracy: 0.8840\n",
      "Epoch 175/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4105 - accuracy: 0.8852\n",
      "Epoch 176/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4144 - accuracy: 0.8828\n",
      "Epoch 177/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4052 - accuracy: 0.8872\n",
      "Epoch 178/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4220 - accuracy: 0.8800\n",
      "Epoch 179/180\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.4123 - accuracy: 0.8845\n",
      "Epoch 180/180\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.4056 - accuracy: 0.8857\n",
      "Accuracy in training dataset: {0} 0.8411904573440552\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.7142 - accuracy: 0.7954\n",
      "Accuracy in test dataset : {0} 0.7954444289207458\n"
     ]
    }
   ],
   "source": [
    "lr = 0.067754567\n",
    "Lambda = .0015\n",
    "x_train = x_train.reshape(42000, 1024)\n",
    "x_test = x_test.reshape(18000, 1024)\n",
    "score, model = train_and_test_loop_withDropouts(180, lr, Lambda, x_train)\n",
    "print(\"Accuracy in training dataset: {0}\", score[1])\n",
    "testscore = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "1. Dropout layer has totally reduced the overfitting but also reduced the accuracy. \n",
    "2. Will Add more hidden layers to increase the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding more layers and using adam optimizer\n",
    "\n",
    "def train_and_test_loop_withmoreLayersandAdamOptimizer(iterations, Lambda, verb=True):\n",
    "\n",
    "     #hyperparameters\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "      \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(1024,)))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(hidden_nodes))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(hidden_nodes))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(x_train, y_train, verbose=0)\n",
    "    # Fit the model   \n",
    "    return score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 2.8899 - accuracy: 0.1199\n",
      "Epoch 2/120\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 2.4110 - accuracy: 0.1867\n",
      "Epoch 3/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 2.0148 - accuracy: 0.3096\n",
      "Epoch 4/120\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 1.7479 - accuracy: 0.4182\n",
      "Epoch 5/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.5752 - accuracy: 0.4895\n",
      "Epoch 6/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.4566 - accuracy: 0.5403 0s - los - ETA: 0s - loss: 1.4590 - accuracy: \n",
      "Epoch 7/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.3595 - accuracy: 0.5757\n",
      "Epoch 8/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.2787 - accuracy: 0.6072\n",
      "Epoch 9/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.2280 - accuracy: 0.6253\n",
      "Epoch 10/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.1630 - accuracy: 0.6452\n",
      "Epoch 11/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.1186 - accuracy: 0.6625\n",
      "Epoch 12/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.0774 - accuracy: 0.6767\n",
      "Epoch 13/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.0390 - accuracy: 0.6891\n",
      "Epoch 14/120\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 1.0122 - accuracy: 0.6971 1s - loss:\n",
      "Epoch 15/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.9845 - accuracy: 0.7089\n",
      "Epoch 16/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.9594 - accuracy: 0.7151\n",
      "Epoch 17/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.9465 - accuracy: 0.7193\n",
      "Epoch 18/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.9253 - accuracy: 0.7248\n",
      "Epoch 19/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.9033 - accuracy: 0.7324\n",
      "Epoch 20/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.8825 - accuracy: 0.7389 1s - loss: 0.8881 - accura - ETA: 0s\n",
      "Epoch 21/120\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.8715 - accuracy: 0.7434\n",
      "Epoch 22/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.8675 - accuracy: 0.7439\n",
      "Epoch 23/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.8514 - accuracy: 0.7476\n",
      "Epoch 24/120\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.8373 - accuracy: 0.7529\n",
      "Epoch 25/120\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.8352 - accuracy: 0.7540\n",
      "Epoch 26/120\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.8129 - accuracy: 0.7598\n",
      "Epoch 27/120\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.8099 - accuracy: 0.7609\n",
      "Epoch 28/120\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.8030 - accuracy: 0.7624\n",
      "Epoch 29/120\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.7874 - accuracy: 0.7686\n",
      "Epoch 30/120\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.7863 - accuracy: 0.7668\n",
      "Epoch 31/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.7828 - accuracy: 0.7706\n",
      "Epoch 32/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.7681 - accuracy: 0.7729\n",
      "Epoch 33/120\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.7594 - accuracy: 0.7774\n",
      "Epoch 34/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.7576 - accuracy: 0.7787\n",
      "Epoch 35/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.7442 - accuracy: 0.7808\n",
      "Epoch 36/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.7452 - accuracy: 0.7797\n",
      "Epoch 37/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.7486 - accuracy: 0.7794\n",
      "Epoch 38/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.7326 - accuracy: 0.7842\n",
      "Epoch 39/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.7295 - accuracy: 0.7836 0s - loss: 0.730\n",
      "Epoch 40/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.7262 - accuracy: 0.7873 0s - loss: 0.7259 - \n",
      "Epoch 41/120\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.7195 - accuracy: 0.7890\n",
      "Epoch 42/120\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.7185 - accuracy: 0.7889\n",
      "Epoch 43/120\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.7082 - accuracy: 0.7924\n",
      "Epoch 44/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.7062 - accuracy: 0.7908\n",
      "Epoch 45/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6970 - accuracy: 0.7969\n",
      "Epoch 46/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.7011 - accuracy: 0.7947 1s - loss: 0 - ETA: 0s - loss: 0.6972 \n",
      "Epoch 47/120\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.6917 - accuracy: 0.7948\n",
      "Epoch 48/120\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.6926 - accuracy: 0.7939\n",
      "Epoch 49/120\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.6896 - accuracy: 0.7968\n",
      "Epoch 50/120\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.6836 - accuracy: 0.7973\n",
      "Epoch 51/120\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.6805 - accuracy: 0.8003\n",
      "Epoch 52/120\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.6819 - accuracy: 0.7976\n",
      "Epoch 53/120\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.6837 - accuracy: 0.7985\n",
      "Epoch 54/120\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.6722 - accuracy: 0.8030 0s - loss: 0.6661 - accuracy: 0.80 - ETA: 0s - l\n",
      "Epoch 55/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6763 - accuracy: 0.7992\n",
      "Epoch 56/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6636 - accuracy: 0.8046\n",
      "Epoch 57/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6634 - accuracy: 0.8046\n",
      "Epoch 58/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6624 - accuracy: 0.8036\n",
      "Epoch 59/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6627 - accuracy: 0.8038\n",
      "Epoch 60/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6591 - accuracy: 0.8053 0s - l\n",
      "Epoch 61/120\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.6557 - accuracy: 0.8051\n",
      "Epoch 62/120\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.6579 - accuracy: 0.8042\n",
      "Epoch 63/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6430 - accuracy: 0.8085\n",
      "Epoch 64/120\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.6475 - accuracy: 0.8079\n",
      "Epoch 65/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6445 - accuracy: 0.8081\n",
      "Epoch 66/120\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.6482 - accuracy: 0.8073\n",
      "Epoch 67/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6382 - accuracy: 0.8110\n",
      "Epoch 68/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6387 - accuracy: 0.8102\n",
      "Epoch 69/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6403 - accuracy: 0.8086\n",
      "Epoch 70/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6337 - accuracy: 0.8136\n",
      "Epoch 71/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6341 - accuracy: 0.8111\n",
      "Epoch 72/120\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.6283 - accuracy: 0.8130\n",
      "Epoch 73/120\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.6301 - accuracy: 0.8133\n",
      "Epoch 74/120\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.6281 - accuracy: 0.8135\n",
      "Epoch 75/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6246 - accuracy: 0.8156\n",
      "Epoch 76/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6242 - accuracy: 0.8142\n",
      "Epoch 77/120\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.6199 - accuracy: 0.8154\n",
      "Epoch 78/120\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.6205 - accuracy: 0.8146\n",
      "Epoch 79/120\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.6235 - accuracy: 0.8156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.6180 - accuracy: 0.8159\n",
      "Epoch 81/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.6244 - accuracy: 0.8145\n",
      "Epoch 82/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.6236 - accuracy: 0.8157\n",
      "Epoch 83/120\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.6115 - accuracy: 0.8180\n",
      "Epoch 84/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.6115 - accuracy: 0.8183\n",
      "Epoch 85/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.6079 - accuracy: 0.8196 1s - los\n",
      "Epoch 86/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.6074 - accuracy: 0.8206\n",
      "Epoch 87/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.6084 - accuracy: 0.8195\n",
      "Epoch 88/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.6057 - accuracy: 0.8195\n",
      "Epoch 89/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.6101 - accuracy: 0.8185\n",
      "Epoch 90/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.6021 - accuracy: 0.8209\n",
      "Epoch 91/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.6058 - accuracy: 0.8201\n",
      "Epoch 92/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.6000 - accuracy: 0.8228\n",
      "Epoch 93/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.5996 - accuracy: 0.8213\n",
      "Epoch 94/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.5965 - accuracy: 0.8240\n",
      "Epoch 95/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.5909 - accuracy: 0.8265\n",
      "Epoch 96/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.5988 - accuracy: 0.8198\n",
      "Epoch 97/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.5958 - accuracy: 0.8215\n",
      "Epoch 98/120\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.5930 - accuracy: 0.8244\n",
      "Epoch 99/120\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.5924 - accuracy: 0.8236\n",
      "Epoch 100/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.6019 - accuracy: 0.8232\n",
      "Epoch 101/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.5863 - accuracy: 0.8242\n",
      "Epoch 102/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.5868 - accuracy: 0.8239\n",
      "Epoch 103/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.5987 - accuracy: 0.8213\n",
      "Epoch 104/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.5909 - accuracy: 0.8244\n",
      "Epoch 105/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.5802 - accuracy: 0.8270\n",
      "Epoch 106/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.5823 - accuracy: 0.8266\n",
      "Epoch 107/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.5827 - accuracy: 0.8286\n",
      "Epoch 108/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.5791 - accuracy: 0.8276\n",
      "Epoch 109/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.5779 - accuracy: 0.8276 0s - los\n",
      "Epoch 110/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.5793 - accuracy: 0.8283\n",
      "Epoch 111/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.5799 - accuracy: 0.8270\n",
      "Epoch 112/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.5757 - accuracy: 0.8289\n",
      "Epoch 113/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.5744 - accuracy: 0.8275 0s - l\n",
      "Epoch 114/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.5782 - accuracy: 0.8271\n",
      "Epoch 115/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.5821 - accuracy: 0.8263\n",
      "Epoch 116/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.5697 - accuracy: 0.8307\n",
      "Epoch 117/120\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.5769 - accuracy: 0.8283\n",
      "Epoch 118/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.5742 - accuracy: 0.8287 0s\n",
      "Epoch 119/120\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.5703 - accuracy: 0.8311\n",
      "Epoch 120/120\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.5725 - accuracy: 0.8302\n",
      "Accuracy in training dataset: {0} 0.8161666393280029\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.7672 - accuracy: 0.7790\n",
      "Accuracy in test dataset : {0} 0.7789999842643738\n"
     ]
    }
   ],
   "source": [
    "Lambda = 0.015\n",
    "x_train = x_train.reshape(42000, 1024)\n",
    "x_test = x_test.reshape(18000, 1024)\n",
    "score, model = train_and_test_loop_withmoreLayersandAdamOptimizer(120, Lambda)\n",
    "print(\"Accuracy in training dataset: {0}\", score[1])\n",
    "testscore = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding more layers\n",
    "\n",
    "def train_and_test_loop_withmoreLayersandAdamOptimizer1(iterations, Lambda, verb=True):\n",
    "\n",
    "     #hyperparameters\n",
    "    hidden_nodes = 300\n",
    "    output_nodes = 10\n",
    "      \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(1024,)))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(hidden_nodes))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(hidden_nodes))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(x_train, y_train, verbose=0)\n",
    "    # Fit the model   \n",
    "    return score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 2.2854 - accuracy: 0.2275\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 1.5178 - accuracy: 0.4910\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.1995 - accuracy: 0.6140\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.0592 - accuracy: 0.6674\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.9797 - accuracy: 0.6976\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.9143 - accuracy: 0.7204\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 3s 73ms/step - loss: 0.8570 - accuracy: 0.7373\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 0.8218 - accuracy: 0.7468\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 3s 73ms/step - loss: 0.7827 - accuracy: 0.7608\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 0.7567 - accuracy: 0.7680\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 0.7358 - accuracy: 0.7758\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 0.7126 - accuracy: 0.7827\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 0.6915 - accuracy: 0.7890\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 3s 73ms/step - loss: 0.6797 - accuracy: 0.7918\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.6597 - accuracy: 0.7988\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.6388 - accuracy: 0.8045\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 0.6354 - accuracy: 0.8065\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.6100 - accuracy: 0.8144\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 0.6016 - accuracy: 0.8159\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 0.5867 - accuracy: 0.8204\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.5758 - accuracy: 0.8263\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.5589 - accuracy: 0.8308\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.5702 - accuracy: 0.8246\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.5560 - accuracy: 0.8290\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 0.5497 - accuracy: 0.8334\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 0.5387 - accuracy: 0.8366\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 0.5322 - accuracy: 0.8378\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.5289 - accuracy: 0.8379\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 0.5179 - accuracy: 0.8422\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.5153 - accuracy: 0.8418\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 0.5069 - accuracy: 0.8457\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.4969 - accuracy: 0.8493\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.4955 - accuracy: 0.8488\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.4889 - accuracy: 0.8486\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.4909 - accuracy: 0.8496\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.4852 - accuracy: 0.8517\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.4781 - accuracy: 0.8540\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.4656 - accuracy: 0.8570\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 0.4660 - accuracy: 0.8562\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 0.4617 - accuracy: 0.8612\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.4537 - accuracy: 0.8625\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.4594 - accuracy: 0.8602\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 0.4484 - accuracy: 0.8631\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 0.4467 - accuracy: 0.8634\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 3s 83ms/step - loss: 0.4473 - accuracy: 0.8623 0s - loss: 0.443\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 0.4342 - accuracy: 0.8660\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.4303 - accuracy: 0.8684\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 4s 87ms/step - loss: 0.4324 - accuracy: 0.8679\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 0.4274 - accuracy: 0.8702\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.4253 - accuracy: 0.8716\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 4s 84ms/step - loss: 0.4171 - accuracy: 0.8713\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 0.4115 - accuracy: 0.8728\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.4154 - accuracy: 0.8733\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.4132 - accuracy: 0.8733\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 0.4091 - accuracy: 0.8750\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 0.4007 - accuracy: 0.8767\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 0.4022 - accuracy: 0.8759\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 0.3971 - accuracy: 0.8777\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.4035 - accuracy: 0.8760\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 0.4019 - accuracy: 0.8766\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.3927 - accuracy: 0.8795\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 4s 84ms/step - loss: 0.3928 - accuracy: 0.8785\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.3914 - accuracy: 0.8793\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.3874 - accuracy: 0.8799\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.3824 - accuracy: 0.8835\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.3864 - accuracy: 0.8799\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.3861 - accuracy: 0.8810\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.3788 - accuracy: 0.8834\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.3718 - accuracy: 0.8874\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.3790 - accuracy: 0.8831\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.3708 - accuracy: 0.8861\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.3680 - accuracy: 0.8859\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.3640 - accuracy: 0.8864\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.3614 - accuracy: 0.8891\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 3s 83ms/step - loss: 0.3618 - accuracy: 0.8868\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 3s 83ms/step - loss: 0.3549 - accuracy: 0.8910 0s - loss: 0.3547 - accuracy\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 0.3624 - accuracy: 0.8874\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 0.3597 - accuracy: 0.8890\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 0.3541 - accuracy: 0.8897\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 0.3502 - accuracy: 0.8928\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3485 - accuracy: 0.8930\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3544 - accuracy: 0.8919\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.3432 - accuracy: 0.8945\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.3508 - accuracy: 0.8912\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.3413 - accuracy: 0.8947\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.3382 - accuracy: 0.8965\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3434 - accuracy: 0.8939\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3366 - accuracy: 0.8964\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3347 - accuracy: 0.8970\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3415 - accuracy: 0.8937\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3314 - accuracy: 0.8974\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3375 - accuracy: 0.8940\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3371 - accuracy: 0.8960\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.3266 - accuracy: 0.8981\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.3309 - accuracy: 0.8986\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3234 - accuracy: 0.9002\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3266 - accuracy: 0.8995\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.3233 - accuracy: 0.9006\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3331 - accuracy: 0.8975\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.3262 - accuracy: 0.8993\n",
      "Accuracy in training dataset: {0} 0.8299285769462585\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 0.7209 - accuracy: 0.7792\n",
      "Accuracy in test dataset : {0} 0.7791666388511658\n"
     ]
    }
   ],
   "source": [
    "Lambda = 0.0015\n",
    "x_train = x_train.reshape(42000, 1024)\n",
    "x_test = x_test.reshape(18000, 1024)\n",
    "score, model = train_and_test_loop_withmoreLayersandAdamOptimizer1(100, Lambda)\n",
    "print(\"Accuracy in training dataset: {0}\", score[1])\n",
    "testscore = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "1. As layers increases computational time increases and the model start becoming overfit but the accuracy also increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to see the accuracy on the best combination of learning rate and lambda in validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was so far the best model that has given best accuracy\n",
    "def train_and_test_loopFinalwithValidationData(iterations, lr, Lambda, verb=True):\n",
    "\n",
    "     #hyperparameters\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "      \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(1024,)))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu'))  \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(hidden_nodes))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=learning_rate)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer= sgd , metrics=['accuracy'])\n",
    "    model.fit(x_val, y_val, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(x_val, y_val, verbose=0)\n",
    "    \n",
    "    # Fit the model   \n",
    "    return score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.6126 - accuracy: 0.1166\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.4152 - accuracy: 0.1539\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.3201 - accuracy: 0.1873\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2222 - accuracy: 0.2233\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 2.1480 - accuracy: 0.2573\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.0696 - accuracy: 0.2877\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.9957 - accuracy: 0.3209 0s - loss: 1.9991 - accuracy\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 1.9334 - accuracy: 0.3469\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.8680 - accuracy: 0.3739\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.8103 - accuracy: 0.3981\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.7543 - accuracy: 0.4213\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.7065 - accuracy: 0.4424\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.6576 - accuracy: 0.4633\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.6161 - accuracy: 0.4824\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.5760 - accuracy: 0.4970\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.5411 - accuracy: 0.5144\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.5047 - accuracy: 0.5255\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.4768 - accuracy: 0.5409\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 1.4465 - accuracy: 0.5507 0s - loss: 1.4467 - accuracy: \n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 1.4223 - accuracy: 0.5597\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.3931 - accuracy: 0.5715\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.3686 - accuracy: 0.5800\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.3492 - accuracy: 0.5877\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.3291 - accuracy: 0.5932\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.3058 - accuracy: 0.6042\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.2828 - accuracy: 0.6109\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.2732 - accuracy: 0.6148\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.2510 - accuracy: 0.6222\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.2409 - accuracy: 0.6253\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.2256 - accuracy: 0.6312 0s - loss: 1.2\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.2081 - accuracy: 0.6395\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.1982 - accuracy: 0.6414 0s - loss: 1.1980 - accura\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.1832 - accuracy: 0.6466\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 1.1701 - accuracy: 0.6505\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.1562 - accuracy: 0.6535\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.1424 - accuracy: 0.6593 1s\n",
      "Epoch 37/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.1416 - accuracy: 0.6614\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.1257 - accuracy: 0.6646\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.1198 - accuracy: 0.6686\n",
      "Epoch 40/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.1080 - accuracy: 0.6680\n",
      "Epoch 41/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 1.1011 - accuracy: 0.6761\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.0875 - accuracy: 0.6768\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.0784 - accuracy: 0.6837\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.0662 - accuracy: 0.6856\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.0580 - accuracy: 0.6900\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.0529 - accuracy: 0.6909\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.0436 - accuracy: 0.6932\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.0357 - accuracy: 0.6954\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 1.0326 - accuracy: 0.6954\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.0225 - accuracy: 0.6983\n",
      "Epoch 51/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.0152 - accuracy: 0.6997\n",
      "Epoch 52/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.0084 - accuracy: 0.7045\n",
      "Epoch 53/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0002 - accuracy: 0.7070\n",
      "Epoch 54/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.9927 - accuracy: 0.7073\n",
      "Epoch 55/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.9893 - accuracy: 0.7095\n",
      "Epoch 56/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.9868 - accuracy: 0.7093\n",
      "Epoch 57/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.9775 - accuracy: 0.7138\n",
      "Epoch 58/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.9777 - accuracy: 0.7130\n",
      "Epoch 59/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.9636 - accuracy: 0.7173\n",
      "Epoch 60/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.9629 - accuracy: 0.7191\n",
      "Epoch 61/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.9527 - accuracy: 0.7203\n",
      "Epoch 62/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.9488 - accuracy: 0.7242\n",
      "Epoch 63/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.9441 - accuracy: 0.7268\n",
      "Epoch 64/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.9441 - accuracy: 0.7236 0s - loss: 0.940\n",
      "Epoch 65/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.9332 - accuracy: 0.7276\n",
      "Epoch 66/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.9303 - accuracy: 0.7264\n",
      "Epoch 67/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.9198 - accuracy: 0.7300\n",
      "Epoch 68/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.9180 - accuracy: 0.7306\n",
      "Epoch 69/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.9199 - accuracy: 0.7293 0s - loss:\n",
      "Epoch 70/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.9092 - accuracy: 0.7330\n",
      "Epoch 71/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.9095 - accuracy: 0.7328\n",
      "Epoch 72/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.8990 - accuracy: 0.7369\n",
      "Epoch 73/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.8966 - accuracy: 0.7387\n",
      "Epoch 74/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.8924 - accuracy: 0.7406\n",
      "Epoch 75/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.8889 - accuracy: 0.7408\n",
      "Epoch 76/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.8840 - accuracy: 0.7421\n",
      "Epoch 77/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.8803 - accuracy: 0.7432\n",
      "Epoch 78/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.8768 - accuracy: 0.7454\n",
      "Epoch 79/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.8668 - accuracy: 0.7466\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 45ms/step - loss: 0.8673 - accuracy: 0.7493\n",
      "Epoch 81/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.8668 - accuracy: 0.7479\n",
      "Epoch 82/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.8619 - accuracy: 0.7496\n",
      "Epoch 83/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.8607 - accuracy: 0.7508\n",
      "Epoch 84/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.8489 - accuracy: 0.7526\n",
      "Epoch 85/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.8503 - accuracy: 0.7540\n",
      "Epoch 86/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.8458 - accuracy: 0.7551\n",
      "Epoch 87/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.8459 - accuracy: 0.7547\n",
      "Epoch 88/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.8333 - accuracy: 0.7588\n",
      "Epoch 89/200\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.8363 - accuracy: 0.7584\n",
      "Epoch 90/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.8323 - accuracy: 0.7583\n",
      "Epoch 91/200\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 0.8307 - accuracy: 0.7598\n",
      "Epoch 92/200\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 0.8276 - accuracy: 0.7618\n",
      "Epoch 93/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.8255 - accuracy: 0.7599\n",
      "Epoch 94/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.8219 - accuracy: 0.7621\n",
      "Epoch 95/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.8180 - accuracy: 0.7632\n",
      "Epoch 96/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.8144 - accuracy: 0.7659\n",
      "Epoch 97/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.8099 - accuracy: 0.7666\n",
      "Epoch 98/200\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.8041 - accuracy: 0.7668\n",
      "Epoch 99/200\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.8069 - accuracy: 0.7651 0s - loss:\n",
      "Epoch 100/200\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.8001 - accuracy: 0.7684\n",
      "Epoch 101/200\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.7956 - accuracy: 0.7690\n",
      "Epoch 102/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.7993 - accuracy: 0.7680\n",
      "Epoch 103/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.7926 - accuracy: 0.7708\n",
      "Epoch 104/200\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.7953 - accuracy: 0.7709\n",
      "Epoch 105/200\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.7912 - accuracy: 0.7722\n",
      "Epoch 106/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.7889 - accuracy: 0.7712\n",
      "Epoch 107/200\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.7834 - accuracy: 0.7745\n",
      "Epoch 108/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.7778 - accuracy: 0.7760\n",
      "Epoch 109/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.7760 - accuracy: 0.7749\n",
      "Epoch 110/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.7754 - accuracy: 0.7775\n",
      "Epoch 111/200\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.7678 - accuracy: 0.7789\n",
      "Epoch 112/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.7681 - accuracy: 0.7776\n",
      "Epoch 113/200\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.7667 - accuracy: 0.7780\n",
      "Epoch 114/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.7617 - accuracy: 0.7802\n",
      "Epoch 115/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.7677 - accuracy: 0.7792\n",
      "Epoch 116/200\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.7626 - accuracy: 0.7780\n",
      "Epoch 117/200\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 0.7547 - accuracy: 0.7823\n",
      "Epoch 118/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.7555 - accuracy: 0.7830\n",
      "Epoch 119/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.7521 - accuracy: 0.7820\n",
      "Epoch 120/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.7473 - accuracy: 0.7872\n",
      "Epoch 121/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.7461 - accuracy: 0.7867\n",
      "Epoch 122/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.7443 - accuracy: 0.7842\n",
      "Epoch 123/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.7426 - accuracy: 0.7876\n",
      "Epoch 124/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.7425 - accuracy: 0.7854\n",
      "Epoch 125/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.7417 - accuracy: 0.7850\n",
      "Epoch 126/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.7393 - accuracy: 0.7861\n",
      "Epoch 127/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.7355 - accuracy: 0.7891\n",
      "Epoch 128/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7274 - accuracy: 0.7918\n",
      "Epoch 129/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.7313 - accuracy: 0.7878\n",
      "Epoch 130/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.7296 - accuracy: 0.7902\n",
      "Epoch 131/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.7289 - accuracy: 0.7903\n",
      "Epoch 132/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.7247 - accuracy: 0.7898\n",
      "Epoch 133/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.7212 - accuracy: 0.7915\n",
      "Epoch 134/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.7223 - accuracy: 0.7937\n",
      "Epoch 135/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.7194 - accuracy: 0.7942\n",
      "Epoch 136/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.7166 - accuracy: 0.7957\n",
      "Epoch 137/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.7153 - accuracy: 0.7930\n",
      "Epoch 138/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.7147 - accuracy: 0.7947\n",
      "Epoch 139/200\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.7124 - accuracy: 0.7958\n",
      "Epoch 140/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.7075 - accuracy: 0.7966\n",
      "Epoch 141/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.7085 - accuracy: 0.7965\n",
      "Epoch 142/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.7008 - accuracy: 0.7982\n",
      "Epoch 143/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.7105 - accuracy: 0.7964\n",
      "Epoch 144/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.7010 - accuracy: 0.7987\n",
      "Epoch 145/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.7024 - accuracy: 0.7991\n",
      "Epoch 146/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6994 - accuracy: 0.8006\n",
      "Epoch 147/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6969 - accuracy: 0.7991\n",
      "Epoch 148/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6989 - accuracy: 0.8003\n",
      "Epoch 149/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6938 - accuracy: 0.8009\n",
      "Epoch 150/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6955 - accuracy: 0.7996\n",
      "Epoch 151/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6923 - accuracy: 0.8018 0s - loss: 0.692\n",
      "Epoch 152/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6835 - accuracy: 0.8035\n",
      "Epoch 153/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6899 - accuracy: 0.8021\n",
      "Epoch 154/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6852 - accuracy: 0.8056\n",
      "Epoch 155/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6852 - accuracy: 0.8028\n",
      "Epoch 156/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6841 - accuracy: 0.8032\n",
      "Epoch 157/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6850 - accuracy: 0.8046\n",
      "Epoch 158/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6817 - accuracy: 0.8050\n",
      "Epoch 159/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6786 - accuracy: 0.8066\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6753 - accuracy: 0.8071\n",
      "Epoch 161/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6762 - accuracy: 0.8078\n",
      "Epoch 162/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6716 - accuracy: 0.8085\n",
      "Epoch 163/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6717 - accuracy: 0.8081 0s - loss: 0.670\n",
      "Epoch 164/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6690 - accuracy: 0.8099\n",
      "Epoch 165/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6677 - accuracy: 0.8068\n",
      "Epoch 166/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6658 - accuracy: 0.8088\n",
      "Epoch 167/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6682 - accuracy: 0.8096\n",
      "Epoch 168/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6643 - accuracy: 0.8085\n",
      "Epoch 169/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6612 - accuracy: 0.8108\n",
      "Epoch 170/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6589 - accuracy: 0.8108\n",
      "Epoch 171/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6561 - accuracy: 0.8131 1s -\n",
      "Epoch 172/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.6576 - accuracy: 0.8122\n",
      "Epoch 173/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6576 - accuracy: 0.8102\n",
      "Epoch 174/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6576 - accuracy: 0.8116 \n",
      "Epoch 175/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.6551 - accuracy: 0.8144\n",
      "Epoch 176/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.6537 - accuracy: 0.8113\n",
      "Epoch 177/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6505 - accuracy: 0.8126\n",
      "Epoch 178/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6520 - accuracy: 0.8147\n",
      "Epoch 179/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.6482 - accuracy: 0.8150\n",
      "Epoch 180/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6500 - accuracy: 0.8155\n",
      "Epoch 181/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6446 - accuracy: 0.8186\n",
      "Epoch 182/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6457 - accuracy: 0.8151 1s - loss: 0.6341  - ETA: 0s - loss:\n",
      "Epoch 183/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6436 - accuracy: 0.8161\n",
      "Epoch 184/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6426 - accuracy: 0.8160\n",
      "Epoch 185/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6397 - accuracy: 0.8173\n",
      "Epoch 186/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6417 - accuracy: 0.8155\n",
      "Epoch 187/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6404 - accuracy: 0.8162\n",
      "Epoch 188/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6377 - accuracy: 0.8193\n",
      "Epoch 189/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6411 - accuracy: 0.8194\n",
      "Epoch 190/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.6369 - accuracy: 0.8186\n",
      "Epoch 191/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.6357 - accuracy: 0.8172\n",
      "Epoch 192/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6362 - accuracy: 0.8193\n",
      "Epoch 193/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6317 - accuracy: 0.8198\n",
      "Epoch 194/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6318 - accuracy: 0.8196\n",
      "Epoch 195/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6312 - accuracy: 0.8183\n",
      "Epoch 196/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6285 - accuracy: 0.8216\n",
      "Epoch 197/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.6259 - accuracy: 0.8217\n",
      "Epoch 198/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6235 - accuracy: 0.8218\n",
      "Epoch 199/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6241 - accuracy: 0.8221\n",
      "Epoch 200/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.6233 - accuracy: 0.8218\n",
      "Accuracy in validation dataset: {0} 0.8614500164985657\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 0.6056 - accuracy: 0.8352\n",
      "Accuracy in test dataset : {0} 0.8352222442626953\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "Lambda = .0015\n",
    "x_val = x_val.reshape(60000, 1024)\n",
    "x_test = x_test.reshape(18000, 1024)\n",
    "score, model = train_and_test_loopFinalwithValidationData(200, lr, Lambda)\n",
    "print(\"Accuracy in validation dataset: {0}\", score[1])\n",
    "testscore = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "1. The accuracy results are almost the same in validation and training set. But in validation it is slightly better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  So far we have hit and trial the value of learning rate and lambda.  Now since we have finalized out model, lets try for different range of value for learning rate and lambda, for getting better accuracy results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_loopBestAccuracy(iterations, lr, Lambda, verb=True):\n",
    "\n",
    "     #hyperparameters\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "      \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(1024,)))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu'))  \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(hidden_nodes))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=learning_rate)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer= sgd , metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(x_train, y_train, verbose=0)\n",
    "    \n",
    "    # Fit the model   \n",
    "    return score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0990\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997: 0s - loss: nan - accura\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997: 1s - loss: n\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997: 1s - loss: nan\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - ETA: 0s - loss: nan - accuracy: 0.099 - 3s 61ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 2s 54ms/step - loss: nan - accuracy: 0.0997: 1s - lo\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997: 1s - loss: n\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 2s 51ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997: 0s - loss: nan - accuracy: 0.1\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997: 0s - loss: nan - accuracy: 0.099\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997: 1s - loss:\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Try 1/100: Best_val_acc: [nan, 0.09966666996479034], lr: 8019.1998133032275, Lambda: 0.3849671230512033\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.1003   \n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 2s 51ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997: 1s - loss: \n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997: 1s - loss: nan \n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Try 2/100: Best_val_acc: [nan, 0.09966666996479034], lr: 686.6125409564041, Lambda: 7.154256506188128\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 8.2752 - accuracy: 0.1060\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 5.9532 - accuracy: 0.1245\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 4.5464 - accuracy: 0.1437\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 3.6801 - accuracy: 0.1608\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 3.1447 - accuracy: 0.1736 0s - loss: 3.1718 - accuracy\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.8133 - accuracy: 0.1885\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.6080 - accuracy: 0.2073\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.4785 - accuracy: 0.2235\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 2.3994 - accuracy: 0.2371\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.3493 - accuracy: 0.2497\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.3166 - accuracy: 0.2642\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2963 - accuracy: 0.2764\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2827 - accuracy: 0.2836\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.2741 - accuracy: 0.2894\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2676 - accuracy: 0.2945\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.2625 - accuracy: 0.2992\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2585 - accuracy: 0.3025\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2544 - accuracy: 0.3074\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2515 - accuracy: 0.3115\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2492 - accuracy: 0.3139\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.2458 - accuracy: 0.3150\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.2427 - accuracy: 0.3208\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.2401 - accuracy: 0.3221\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2374 - accuracy: 0.3229\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2341 - accuracy: 0.3267\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2303 - accuracy: 0.3269 \n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2277 - accuracy: 0.3269\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2242 - accuracy: 0.3351\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.2218 - accuracy: 0.3325\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.2169 - accuracy: 0.3390\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.2140 - accuracy: 0.3408\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2103 - accuracy: 0.3444\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2067 - accuracy: 0.3474 0s - loss: 2.2072 - accuracy: \n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.2030 - accuracy: 0.3467\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.1988 - accuracy: 0.3520\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.1953 - accuracy: 0.3535 1s\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.1916 - accuracy: 0.3536\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.1880 - accuracy: 0.3617\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 2.1836 - accuracy: 0.3611\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.1801 - accuracy: 0.3632\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.1766 - accuracy: 0.3638\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.1728 - accuracy: 0.3698\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.1698 - accuracy: 0.3689\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 46ms/step - loss: 2.1646 - accuracy: 0.3706\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.1613 - accuracy: 0.3779\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.1571 - accuracy: 0.3774\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.1531 - accuracy: 0.3823\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.1495 - accuracy: 0.3813\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.1455 - accuracy: 0.3871\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.1428 - accuracy: 0.3875\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.1374 - accuracy: 0.3883\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.1349 - accuracy: 0.3926\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.1307 - accuracy: 0.3938\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.1268 - accuracy: 0.3961\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.1229 - accuracy: 0.4006\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.1201 - accuracy: 0.4025\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.1161 - accuracy: 0.4042\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.1117 - accuracy: 0.4036\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.1092 - accuracy: 0.4099\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.1049 - accuracy: 0.4105\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.1018 - accuracy: 0.4131\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.0989 - accuracy: 0.4111\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.0949 - accuracy: 0.4192\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.0923 - accuracy: 0.4173\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.0879 - accuracy: 0.4206\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.0857 - accuracy: 0.4205\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.0809 - accuracy: 0.4258\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.0769 - accuracy: 0.4282 0s - loss: 2.0\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.0738 - accuracy: 0.4305\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.0720 - accuracy: 0.4330\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.0683 - accuracy: 0.4350\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.0649 - accuracy: 0.4373\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.0617 - accuracy: 0.4376\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.0587 - accuracy: 0.4398\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.0558 - accuracy: 0.4404\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.0520 - accuracy: 0.4454\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.0500 - accuracy: 0.4485\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.0460 - accuracy: 0.4491\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.0434 - accuracy: 0.4517\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.0400 - accuracy: 0.4547\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.0367 - accuracy: 0.4543\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.0347 - accuracy: 0.4551\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.0305 - accuracy: 0.4613 0s - loss: 2.0319 - \n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.0294 - accuracy: 0.4612\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.0271 - accuracy: 0.4619\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.0233 - accuracy: 0.4594\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.0199 - accuracy: 0.4655\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.0171 - accuracy: 0.4697\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.0141 - accuracy: 0.4691\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.0106 - accuracy: 0.4711\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.0088 - accuracy: 0.4728\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.0039 - accuracy: 0.4746\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.0020 - accuracy: 0.4784 1s - l\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.0005 - accuracy: 0.4759\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.9962 - accuracy: 0.4822\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.9943 - accuracy: 0.4804\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.9910 - accuracy: 0.4864\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.9884 - accuracy: 0.4854\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.9863 - accuracy: 0.4863\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.9825 - accuracy: 0.4900\n",
      "Try 3/100: Best_val_acc: [2.465393543243408, 0.106357142329216], lr: 0.007159310789102736, Lambda: 0.3757598106756685\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.1687 - accuracy: 0.2631\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 1.6141 - accuracy: 0.4884\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.3895 - accuracy: 0.5716\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.2578 - accuracy: 0.6202\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1900 - accuracy: 0.64 - 2s 48ms/step - loss: 1.1886 - accuracy: 0.6436\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 1.1195 - accuracy: 0.6670\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.0802 - accuracy: 0.6841\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.0409 - accuracy: 0.6950\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.0127 - accuracy: 0.7056\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.9821 - accuracy: 0.7143\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.9577 - accuracy: 0.7217\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.9386 - accuracy: 0.7315\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.9155 - accuracy: 0.7357\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.8960 - accuracy: 0.7424\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.8888 - accuracy: 0.7445\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.8676 - accuracy: 0.7550\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8511 - accuracy: 0.7595\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.8380 - accuracy: 0.7602 0s - loss: 0.8\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8372 - accuracy: 0.7598\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8199 - accuracy: 0.7664\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.8106 - accuracy: 0.7705\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7931 - accuracy: 0.7757\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7816 - accuracy: 0.7793\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7840 - accuracy: 0.7777\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7668 - accuracy: 0.7846\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7556 - accuracy: 0.7860\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7492 - accuracy: 0.7895\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7430 - accuracy: 0.7890\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7301 - accuracy: 0.7952\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7350 - accuracy: 0.7926\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7181 - accuracy: 0.7968\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7175 - accuracy: 0.7986\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7067 - accuracy: 0.8020\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7075 - accuracy: 0.8017 0s - loss: 0.700\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6840 - accuracy: 0.8080\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6783 - accuracy: 0.8091\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6912 - accuracy: 0.8077\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6726 - accuracy: 0.8122\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6716 - accuracy: 0.8125\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6728 - accuracy: 0.8123\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6575 - accuracy: 0.8164\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6512 - accuracy: 0.8192\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6637 - accuracy: 0.8130\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6282 - accuracy: 0.8258\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6425 - accuracy: 0.8206\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6377 - accuracy: 0.8219\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6305 - accuracy: 0.8229\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6300 - accuracy: 0.8209\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6151 - accuracy: 0.8281\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6169 - accuracy: 0.8257\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6207 - accuracy: 0.8265\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6070 - accuracy: 0.8302\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.5981 - accuracy: 0.8346\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6099 - accuracy: 0.8294\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6014 - accuracy: 0.8320\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5892 - accuracy: 0.8348\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5825 - accuracy: 0.8395 0s - loss: 0.5860 - accuracy: \n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.5885 - accuracy: 0.8365\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5843 - accuracy: 0.8374\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.5837 - accuracy: 0.8376\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5770 - accuracy: 0.8385 0s - loss: 0.5\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5747 - accuracy: 0.8406\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5803 - accuracy: 0.8376\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5572 - accuracy: 0.8445\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5566 - accuracy: 0.8452\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5602 - accuracy: 0.8442\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5442 - accuracy: 0.8489\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5649 - accuracy: 0.8409\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5647 - accuracy: 0.8420 1s\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5523 - accuracy: 0.8472\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5449 - accuracy: 0.8490\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5456 - accuracy: 0.8477\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5542 - accuracy: 0.8463\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5318 - accuracy: 0.8525\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5249 - accuracy: 0.8543\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5314 - accuracy: 0.8521\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5274 - accuracy: 0.8533\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5314 - accuracy: 0.8515\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5236 - accuracy: 0.8556\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.5228 - accuracy: 0.8559\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.5149 - accuracy: 0.8580\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5232 - accuracy: 0.8541\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5133 - accuracy: 0.8581\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5189 - accuracy: 0.8558\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5087 - accuracy: 0.8595\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5181 - accuracy: 0.8560\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5009 - accuracy: 0.8606 0s - loss: 0.4983 - accura\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.5119 - accuracy: 0.8586\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5193 - accuracy: 0.8553\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5010 - accuracy: 0.8614 0s - loss: 0.5014 - accuracy: \n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.4964 - accuracy: 0.8615\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5054 - accuracy: 0.8588\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.4923 - accuracy: 0.8640\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.4951 - accuracy: 0.8609\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.4831 - accuracy: 0.8693 0s - loss: 0.4847 - accuracy\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.4819 - accuracy: 0.8673 0s - loss: 0.4863 - ac\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.4920 - accuracy: 0.8646\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.4904 - accuracy: 0.8651\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.4811 - accuracy: 0.8668\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.4738 - accuracy: 0.8704\n",
      "Try 4/100: Best_val_acc: [2.5390126705169678, 0.09933333098888397], lr: 0.12353364166613577, Lambda: 0.002870272892553188\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.1001     \n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997: 1s - loss: nan - \n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997: 1s - loss: nan - ac\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997: 0s - loss: nan - accuracy: 0.\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997: 0s - loss: nan - accuracy: 0\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997: 0s - loss: nan - accuracy: 0.0\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997: 0s - loss: nan - accuracy: 0.1\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997: 0s - loss: nan - accura\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Try 5/100: Best_val_acc: [nan, 0.09966666996479034], lr: 1.4032031429696872, Lambda: 9.418956033692636\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 339288418097057610954964992.0000 - accuracy: 0.0978\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0993                 \n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997: 0s - loss: nan - accuracy: 0\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997: 0s - loss: nan - accur\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997: 0s - loss: nan - accuracy: 0.\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997: 0s - loss: nan - accurac\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: nan - accuracy: 0.0997: 0s - loss: nan - accu\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997: 0s - loss: nan - accuracy:\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997: 0s - loss: nan - accuracy: 0.1\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: nan - accuracy: 0.0997\n",
      "Try 6/100: Best_val_acc: [nan, 0.09966666996479034], lr: 27.859874206505246, Lambda: 0.04849632669431812\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 11.5079 - accuracy: 0.1010: 0s - loss: 11.5079 - accuracy: 0.101\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 9.9055 - accuracy: 0.1052\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 8.6006 - accuracy: 0.1096\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 7.5278 - accuracy: 0.1145\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 6.6390 - accuracy: 0.1220\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 5.9025 - accuracy: 0.1266\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 5.2931 - accuracy: 0.1270\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 4.7861 - accuracy: 0.1333\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 4.3616 - accuracy: 0.1394\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 4.0125 - accuracy: 0.1420\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 3.7229 - accuracy: 0.1479\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 3.4793 - accuracy: 0.1507 0s - loss: 3.4918 - accuracy: \n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 3.2799 - accuracy: 0.1541\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 3.1106 - accuracy: 0.1611\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.9712 - accuracy: 0.1611\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.8563 - accuracy: 0.1687\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.7608 - accuracy: 0.1709\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.6805 - accuracy: 0.1771\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.6136 - accuracy: 0.1806\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.5587 - accuracy: 0.1839\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.5118 - accuracy: 0.1906\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.4734 - accuracy: 0.1968\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.4421 - accuracy: 0.1994\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.4162 - accuracy: 0.2007\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.3940 - accuracy: 0.2064\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3758 - accuracy: 0.2120\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3601 - accuracy: 0.2145\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.3475 - accuracy: 0.2202 0s - los\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.3370 - accuracy: 0.2262\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.3278 - accuracy: 0.2282\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3207 - accuracy: 0.2313\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.3143 - accuracy: 0.2375\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.3093 - accuracy: 0.2380\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.3045 - accuracy: 0.2429\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.3013 - accuracy: 0.2445\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.2980 - accuracy: 0.2482\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2955 - accuracy: 0.2526\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.2930 - accuracy: 0.2542\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2914 - accuracy: 0.2545\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2894 - accuracy: 0.2591\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2887 - accuracy: 0.2607 1s - los\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 47ms/step - loss: 2.2871 - accuracy: 0.2622 0s - loss: 2.2873 \n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2859 - accuracy: 0.2635\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.2852 - accuracy: 0.2641\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2840 - accuracy: 0.2648\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.2837 - accuracy: 0.2637\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.2828 - accuracy: 0.2690\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2822 - accuracy: 0.26 - 2s 42ms/step - loss: 2.2822 - accuracy: 0.2689\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.2819 - accuracy: 0.2680\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.2815 - accuracy: 0.2679\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.2811 - accuracy: 0.2692\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2805 - accuracy: 0.2698\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.2804 - accuracy: 0.2714\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.2798 - accuracy: 0.2740 1s - l\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2798 - accuracy: 0.2719\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2790 - accuracy: 0.2767\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2789 - accuracy: 0.2713\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2784 - accuracy: 0.2762\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2781 - accuracy: 0.2767\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2777 - accuracy: 0.2785\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2771 - accuracy: 0.2795\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2770 - accuracy: 0.2766\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2767 - accuracy: 0.2804\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2763 - accuracy: 0.2813\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2760 - accuracy: 0.2815\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2757 - accuracy: 0.2835\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2754 - accuracy: 0.2822\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2751 - accuracy: 0.2842\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2747 - accuracy: 0.2842\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.2743 - accuracy: 0.2824\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2741 - accuracy: 0.2854\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2736 - accuracy: 0.2856\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2732 - accuracy: 0.2881\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2727 - accuracy: 0.2883\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2723 - accuracy: 0.2870\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2718 - accuracy: 0.2878\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2722 - accuracy: 0.2850\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.2715 - accuracy: 0.2916\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2707 - accuracy: 0.2895 \n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2708 - accuracy: 0.2898\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2702 - accuracy: 0.2908\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2698 - accuracy: 0.2926\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.2692 - accuracy: 0.2918\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2691 - accuracy: 0.2969\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2687 - accuracy: 0.2935\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2684 - accuracy: 0.2962\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2675 - accuracy: 0.2975\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2672 - accuracy: 0.2983\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2669 - accuracy: 0.2973\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2663 - accuracy: 0.2974\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2662 - accuracy: 0.2981\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2653 - accuracy: 0.3006 0s - loss: 2.2653 - accuracy: 0.\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2647 - accuracy: 0.3007\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2651 - accuracy: 0.2987 0s - loss: 2.2652 - accura\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2642 - accuracy: 0.2983\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2638 - accuracy: 0.2998\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2633 - accuracy: 0.3026\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2629 - accuracy: 0.3037\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2625 - accuracy: 0.3047\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2619 - accuracy: 0.3046\n",
      "Try 7/100: Best_val_acc: [2.3390848636627197, 0.09933333098888397], lr: 0.002142421566746102, Lambda: 0.49174026684420186\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.7141 - accuracy: 0.1038\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.6764 - accuracy: 0.1018\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 2.6258 - accuracy: 0.1072\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 2.6022 - accuracy: 0.1089\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 2.5720 - accuracy: 0.1134\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.5538 - accuracy: 0.1146\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.5330 - accuracy: 0.1166\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.5171 - accuracy: 0.1205\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.5011 - accuracy: 0.1245\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 2.4957 - accuracy: 0.1257\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.4788 - accuracy: 0.1300\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.4619 - accuracy: 0.1312\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 2.4591 - accuracy: 0.1324\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 2.4437 - accuracy: 0.1360 \n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 2.4378 - accuracy: 0.1384\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 2.4237 - accuracy: 0.1436\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.4155 - accuracy: 0.1459\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 2.4003 - accuracy: 0.1487\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.4005 - accuracy: 0.1497\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 52ms/step - loss: 2.3866 - accuracy: 0.1527\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3831 - accuracy: 0.1546 0s - loss: 2.3826 - accura\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.3683 - accuracy: 0.1581\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.3606 - accuracy: 0.1621\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.3487 - accuracy: 0.1679\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.3460 - accuracy: 0.1671\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.3317 - accuracy: 0.1707\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.3212 - accuracy: 0.1726\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.3190 - accuracy: 0.1744\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3120 - accuracy: 0.1835\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3104 - accuracy: 0.1776\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.2971 - accuracy: 0.1843\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.2894 - accuracy: 0.1913\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.2788 - accuracy: 0.1921\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 2.2687 - accuracy: 0.1958\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.2631 - accuracy: 0.1970\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.2587 - accuracy: 0.2010\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.2518 - accuracy: 0.2030\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.2443 - accuracy: 0.2062\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.2399 - accuracy: 0.2086\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.2258 - accuracy: 0.2120\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.2185 - accuracy: 0.2167\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.2090 - accuracy: 0.2190\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.2064 - accuracy: 0.2228\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.1952 - accuracy: 0.2253\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.1920 - accuracy: 0.2303\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.1916 - accuracy: 0.2288\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.1788 - accuracy: 0.2340\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.1724 - accuracy: 0.2375\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.1650 - accuracy: 0.2407\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.1584 - accuracy: 0.2418\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.1508 - accuracy: 0.2448\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.1441 - accuracy: 0.2463\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.1360 - accuracy: 0.2522\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.1282 - accuracy: 0.2535\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.1195 - accuracy: 0.2573\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.1231 - accuracy: 0.2602 1s - l\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.1137 - accuracy: 0.2611\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.1023 - accuracy: 0.2639\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.0962 - accuracy: 0.2697\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.0954 - accuracy: 0.2706\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.0852 - accuracy: 0.2722\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.0750 - accuracy: 0.2772\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.0723 - accuracy: 0.2778\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.0666 - accuracy: 0.2809\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 2.0601 - accuracy: 0.2839\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 2.0533 - accuracy: 0.2880\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.0377 - accuracy: 0.2912\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.0379 - accuracy: 0.2933\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.0299 - accuracy: 0.2976\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.0309 - accuracy: 0.2932\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.0178 - accuracy: 0.3008\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.0138 - accuracy: 0.3020\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.0101 - accuracy: 0.3033\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.0032 - accuracy: 0.3092\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.9944 - accuracy: 0.3135\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 1.9864 - accuracy: 0.3168\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.9865 - accuracy: 0.3145\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.9739 - accuracy: 0.3193\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.9694 - accuracy: 0.3229\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 1.9653 - accuracy: 0.3248\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 1.9536 - accuracy: 0.3284\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.9511 - accuracy: 0.3336\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.9430 - accuracy: 0.3345\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.9429 - accuracy: 0.3355\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.9328 - accuracy: 0.3379\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 1.9263 - accuracy: 0.3415\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.9213 - accuracy: 0.3430\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.9158 - accuracy: 0.3470\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.9078 - accuracy: 0.3482\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.9039 - accuracy: 0.3491\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 1.9006 - accuracy: 0.3523\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 1.8976 - accuracy: 0.3534\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 1.8867 - accuracy: 0.3585\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 1.8836 - accuracy: 0.3579\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 1.8798 - accuracy: 0.3614\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 1.8703 - accuracy: 0.3655\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 1.8673 - accuracy: 0.3660\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 1.8597 - accuracy: 0.3734\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 1.8602 - accuracy: 0.3712\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 50ms/step - loss: 1.8513 - accuracy: 0.3713\n",
      "Try 8/100: Best_val_acc: [2.430185079574585, 0.09980952739715576], lr: 0.0008417164570475702, Lambda: 0.00011828373788279204\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.8073 - accuracy: 0.0996\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.7926 - accuracy: 0.0982\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.7730 - accuracy: 0.1024\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.7613 - accuracy: 0.1021\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.7470 - accuracy: 0.1034\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.7281 - accuracy: 0.1024\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.7152 - accuracy: 0.1044\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.7079 - accuracy: 0.1010\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.6893 - accuracy: 0.1050\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.6812 - accuracy: 0.1069\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.6765 - accuracy: 0.1076\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.6634 - accuracy: 0.1088\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.6518 - accuracy: 0.1060\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.6448 - accuracy: 0.1095 0s - loss: 2\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.6308 - accuracy: 0.1094\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.6316 - accuracy: 0.1081\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.6139 - accuracy: 0.1086\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.6071 - accuracy: 0.1132\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.6093 - accuracy: 0.1091\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.5992 - accuracy: 0.1132\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.5997 - accuracy: 0.1118\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.5934 - accuracy: 0.1126\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.5786 - accuracy: 0.1135\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.5712 - accuracy: 0.1150\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.5639 - accuracy: 0.1190\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.5602 - accuracy: 0.1166\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.5606 - accuracy: 0.1170\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.5490 - accuracy: 0.1169\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 2.5477 - accuracy: 0.1175\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.5481 - accuracy: 0.1171\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 2.5339 - accuracy: 0.1243\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.5341 - accuracy: 0.1210\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.5242 - accuracy: 0.1207\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 2.5209 - accuracy: 0.1222\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.5225 - accuracy: 0.1233\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.5158 - accuracy: 0.1218\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 2.5096 - accuracy: 0.1229\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.5088 - accuracy: 0.1224\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.5086 - accuracy: 0.1230\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.5009 - accuracy: 0.1237\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.4999 - accuracy: 0.1250\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.4856 - accuracy: 0.1287\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.4922 - accuracy: 0.1251\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.4866 - accuracy: 0.1286\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.4789 - accuracy: 0.1294\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.4805 - accuracy: 0.1286\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.4755 - accuracy: 0.1305\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.4693 - accuracy: 0.1316\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.4677 - accuracy: 0.1316\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.4661 - accuracy: 0.1311\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.4584 - accuracy: 0.1343\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.4516 - accuracy: 0.1374\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.4565 - accuracy: 0.1332\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.4536 - accuracy: 0.1361\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.4534 - accuracy: 0.1339\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.4447 - accuracy: 0.1380\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 2.4426 - accuracy: 0.1390\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 2.4409 - accuracy: 0.1385\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 2.4346 - accuracy: 0.1384 0s - loss: 2.4319 \n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 2.4404 - accuracy: 0.1384\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.4352 - accuracy: 0.1408\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.4300 - accuracy: 0.1442\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 2.4275 - accuracy: 0.1425\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.4225 - accuracy: 0.1456\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.4230 - accuracy: 0.1413\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.4157 - accuracy: 0.1460\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.4154 - accuracy: 0.1441\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.4178 - accuracy: 0.1447\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.4165 - accuracy: 0.1454\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.4114 - accuracy: 0.1470\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.4046 - accuracy: 0.1471\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.4026 - accuracy: 0.1491\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.3997 - accuracy: 0.1495 0s - loss: 2.3982 \n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.4041 - accuracy: 0.1506\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.3982 - accuracy: 0.1491\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.3986 - accuracy: 0.1501\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.3903 - accuracy: 0.1529\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.3904 - accuracy: 0.1536\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3880 - accuracy: 0.1525\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3822 - accuracy: 0.1537\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3779 - accuracy: 0.1564\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3772 - accuracy: 0.1548\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.3768 - accuracy: 0.1570\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 2.3736 - accuracy: 0.1588\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3727 - accuracy: 0.1606\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.3748 - accuracy: 0.1596\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3664 - accuracy: 0.1595\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3669 - accuracy: 0.1605\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3680 - accuracy: 0.1582\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3591 - accuracy: 0.1614\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3642 - accuracy: 0.1597\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.3565 - accuracy: 0.1600\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.3498 - accuracy: 0.1672 0s - loss: 2.3501 - accuracy: 0.\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.3491 - accuracy: 0.1622\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.3452 - accuracy: 0.1675\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3464 - accuracy: 0.1680 0s - loss: 2.3467 - accura\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.3428 - accuracy: 0.1683\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.3379 - accuracy: 0.1687\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.3376 - accuracy: 0.1692\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.3391 - accuracy: 0.1704 0s - loss: 2.3382 - accuracy\n",
      "Try 9/100: Best_val_acc: [2.422194480895996, 0.09980952739715576], lr: 0.00022164993730443522, Lambda: 0.0003728360154746872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for k in range(1,10):\n",
    "    lr = math.pow(10, np.random.uniform(-4, 4))\n",
    "    Lambda = math.pow(10, np.random.uniform(-4, 2))\n",
    "    best_acc, model = train_and_test_loopBestAccuracy(100, lr, Lambda, False)\n",
    "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 100, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "1. for lambda =  0.002870272892553188 and lr = 0.12353364166613577, the accuracy is very high, lets try and find out the accourcy in test set\n",
    "2. for higher value of lambda loss is exploding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.1599 - accuracy: 0.2691 0s - loss: 2.295\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.6188 - accuracy: 0.4862\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.3887 - accuracy: 0.5719\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.2582 - accuracy: 0.6215\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.1945 - accuracy: 0.6435\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.1194 - accuracy: 0.6672\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.0970 - accuracy: 0.6760\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0448 - accuracy: 0.6913\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0256 - accuracy: 0.7002\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.9828 - accuracy: 0.7160\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.9818 - accuracy: 0.7128\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.9455 - accuracy: 0.7268 0s - loss: 0.9\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.9271 - accuracy: 0.7341\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.9006 - accuracy: 0.7402\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.8978 - accuracy: 0.7406\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.8779 - accuracy: 0.7469\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.8481 - accuracy: 0.7581\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.8681 - accuracy: 0.7510\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.8276 - accuracy: 0.7644\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.8323 - accuracy: 0.7610\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.8124 - accuracy: 0.7683\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.7953 - accuracy: 0.7759\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7907 - accuracy: 0.7764\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7860 - accuracy: 0.7766\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7689 - accuracy: 0.7832\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7600 - accuracy: 0.7849\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7544 - accuracy: 0.7854\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7296 - accuracy: 0.7946\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.7344 - accuracy: 0.7929\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7305 - accuracy: 0.7940\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7245 - accuracy: 0.7952\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.6999 - accuracy: 0.8053\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.7178 - accuracy: 0.7959\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6952 - accuracy: 0.8057\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6906 - accuracy: 0.8070\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6951 - accuracy: 0.8048\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6898 - accuracy: 0.8065\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6822 - accuracy: 0.8088\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.6700 - accuracy: 0.8128\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6673 - accuracy: 0.8129\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6576 - accuracy: 0.8168\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6601 - accuracy: 0.8148\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6427 - accuracy: 0.8205\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6390 - accuracy: 0.8210\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6567 - accuracy: 0.8141\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6358 - accuracy: 0.8247\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6284 - accuracy: 0.8243\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6290 - accuracy: 0.8240 0s - loss: 0.609\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6185 - accuracy: 0.8271 0s - loss: 0.6052 - accuracy: 0. - ETA: 0s - loss: 0.6104 - accura\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6257 - accuracy: 0.8246\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6068 - accuracy: 0.8305\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6056 - accuracy: 0.8323\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.6159 - accuracy: 0.8259\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6021 - accuracy: 0.8307\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6069 - accuracy: 0.8292\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5827 - accuracy: 0.8400\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5920 - accuracy: 0.8345\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5830 - accuracy: 0.8379\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6004 - accuracy: 0.8322\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5943 - accuracy: 0.8326\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5835 - accuracy: 0.8360\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5910 - accuracy: 0.8326\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5601 - accuracy: 0.8453\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5666 - accuracy: 0.8419\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5558 - accuracy: 0.8469\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5690 - accuracy: 0.8408\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5522 - accuracy: 0.8461\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.5600 - accuracy: 0.8433 0s - loss: 0.5612 - accuracy\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.5488 - accuracy: 0.8485\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.5470 - accuracy: 0.8474\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5555 - accuracy: 0.8442\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5465 - accuracy: 0.8487\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5547 - accuracy: 0.8450\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5463 - accuracy: 0.8465\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5388 - accuracy: 0.8480\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5361 - accuracy: 0.8510\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5263 - accuracy: 0.8545\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5413 - accuracy: 0.8505\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5176 - accuracy: 0.8575 0s - loss: 0.5160 - ac\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5241 - accuracy: 0.8550\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5461 - accuracy: 0.8484\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5129 - accuracy: 0.8577\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5134 - accuracy: 0.8587\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.5174 - accuracy: 0.8569\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.5161 - accuracy: 0.8570\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5059 - accuracy: 0.8606\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.5043 - accuracy: 0.8592\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.4954 - accuracy: 0.8622\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.5192 - accuracy: 0.8555\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5054 - accuracy: 0.8599\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.5115 - accuracy: 0.8580\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.5086 - accuracy: 0.8593\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.4858 - accuracy: 0.8667\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.5044 - accuracy: 0.8604\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.4919 - accuracy: 0.8640\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.4941 - accuracy: 0.8632\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.4879 - accuracy: 0.8653\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.5002 - accuracy: 0.8601\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.4903 - accuracy: 0.8653\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.4863 - accuracy: 0.8661\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 0.7282 - accuracy: 0.7949\n",
      "Accuracy in test dataset : {0} 0.7949444651603699\n"
     ]
    }
   ],
   "source": [
    "lr = 0.12353364166613577\n",
    "Lambda = 0.002870272892553188\n",
    "x_train = x_train.reshape(42000, 1024)\n",
    "x_test = x_test.reshape(18000, 1024)\n",
    "score, model = train_and_test_loopBestAccuracy(100, lr, Lambda)\n",
    "testscore = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### observation\n",
    "\n",
    "1. This model overfits in est set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_loopFinal(iterations, lr, Lambda, verb=True):\n",
    "\n",
    "     #hyperparameters\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "      \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(1024,)))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu'))  \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(hidden_nodes))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=learning_rate)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer= sgd , metrics=['accuracy'])\n",
    "    model.fit(x_val, y_val, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(x_val, y_val, verbose=0)\n",
    "    \n",
    "    # Fit the model   \n",
    "    return score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.6117 - accuracy: 0.1169\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.4154 - accuracy: 0.1520\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 2.3099 - accuracy: 0.1890 0s - loss: 2.3142 - accuracy: \n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 2.2135 - accuracy: 0.2256\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 2.1294 - accuracy: 0.2625\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.0429 - accuracy: 0.2992\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.9630 - accuracy: 0.3296\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.8925 - accuracy: 0.3651\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.8298 - accuracy: 0.3888 1s - los\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.7692 - accuracy: 0.4172\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.7139 - accuracy: 0.4396\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.6624 - accuracy: 0.4599\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.6164 - accuracy: 0.4818\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.5762 - accuracy: 0.4929\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.5382 - accuracy: 0.5119\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.5032 - accuracy: 0.5258\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.4745 - accuracy: 0.5360\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.4443 - accuracy: 0.5469\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.4155 - accuracy: 0.5602\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.3894 - accuracy: 0.5648\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.3694 - accuracy: 0.5759\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.3426 - accuracy: 0.5870\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.3223 - accuracy: 0.5956\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.3060 - accuracy: 0.6015\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.2873 - accuracy: 0.6077\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.2684 - accuracy: 0.6127\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.2511 - accuracy: 0.6190\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.2373 - accuracy: 0.6226\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.2231 - accuracy: 0.6283\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.2086 - accuracy: 0.6345\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.1963 - accuracy: 0.6406\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.1814 - accuracy: 0.6436\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.1711 - accuracy: 0.6470\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.1628 - accuracy: 0.6504\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.1510 - accuracy: 0.6546\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.1361 - accuracy: 0.6630\n",
      "Epoch 37/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.1246 - accuracy: 0.6628\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.1146 - accuracy: 0.6683\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.1020 - accuracy: 0.6714\n",
      "Epoch 40/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0944 - accuracy: 0.6745\n",
      "Epoch 41/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.0864 - accuracy: 0.6755\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0779 - accuracy: 0.6781\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0717 - accuracy: 0.6818\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.0609 - accuracy: 0.6841\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0562 - accuracy: 0.6879\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0480 - accuracy: 0.6865\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0390 - accuracy: 0.6924\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0332 - accuracy: 0.6949\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.0272 - accuracy: 0.6956\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.0186 - accuracy: 0.6988\n",
      "Epoch 51/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0105 - accuracy: 0.7010\n",
      "Epoch 52/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.0049 - accuracy: 0.7032\n",
      "Epoch 53/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.0005 - accuracy: 0.7024\n",
      "Epoch 54/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9912 - accuracy: 0.7072\n",
      "Epoch 55/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.9877 - accuracy: 0.7085\n",
      "Epoch 56/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9817 - accuracy: 0.7104\n",
      "Epoch 57/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9696 - accuracy: 0.7118\n",
      "Epoch 58/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.9717 - accuracy: 0.7145\n",
      "Epoch 59/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9623 - accuracy: 0.7151\n",
      "Epoch 60/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9615 - accuracy: 0.7140\n",
      "Epoch 61/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9549 - accuracy: 0.7192 0s - loss: 0.9513  - ETA: 0s - loss: 0.9522 - accuracy: 0.\n",
      "Epoch 62/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9497 - accuracy: 0.7200\n",
      "Epoch 63/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9475 - accuracy: 0.7204\n",
      "Epoch 64/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.9394 - accuracy: 0.7233 1s - los\n",
      "Epoch 65/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9308 - accuracy: 0.7272\n",
      "Epoch 66/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9272 - accuracy: 0.7268\n",
      "Epoch 67/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9225 - accuracy: 0.7294\n",
      "Epoch 68/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9153 - accuracy: 0.7302\n",
      "Epoch 69/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9191 - accuracy: 0.7309\n",
      "Epoch 70/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9112 - accuracy: 0.7320\n",
      "Epoch 71/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9061 - accuracy: 0.7333\n",
      "Epoch 72/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.9006 - accuracy: 0.7358 0s - loss: 0.8\n",
      "Epoch 73/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.8971 - accuracy: 0.7363\n",
      "Epoch 74/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.8917 - accuracy: 0.7388\n",
      "Epoch 75/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.8900 - accuracy: 0.7391\n",
      "Epoch 76/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.8862 - accuracy: 0.7432\n",
      "Epoch 77/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.8816 - accuracy: 0.7436\n",
      "Epoch 78/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8799 - accuracy: 0.7439\n",
      "Epoch 79/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8767 - accuracy: 0.7433\n",
      "Epoch 80/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.8727 - accuracy: 0.7453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8695 - accuracy: 0.7447\n",
      "Epoch 82/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8655 - accuracy: 0.7442\n",
      "Epoch 83/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8625 - accuracy: 0.7479\n",
      "Epoch 84/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8579 - accuracy: 0.7497\n",
      "Epoch 85/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8557 - accuracy: 0.7496\n",
      "Epoch 86/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8494 - accuracy: 0.7531\n",
      "Epoch 87/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8479 - accuracy: 0.7540\n",
      "Epoch 88/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8407 - accuracy: 0.7543\n",
      "Epoch 89/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8423 - accuracy: 0.7555\n",
      "Epoch 90/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8356 - accuracy: 0.7560\n",
      "Epoch 91/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8316 - accuracy: 0.7596\n",
      "Epoch 92/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8307 - accuracy: 0.7583\n",
      "Epoch 93/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8270 - accuracy: 0.7578\n",
      "Epoch 94/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.8258 - accuracy: 0.7599\n",
      "Epoch 95/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8225 - accuracy: 0.7622\n",
      "Epoch 96/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8203 - accuracy: 0.7610\n",
      "Epoch 97/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8139 - accuracy: 0.7636\n",
      "Epoch 98/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8122 - accuracy: 0.7630\n",
      "Epoch 99/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8117 - accuracy: 0.7630\n",
      "Epoch 100/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.8038 - accuracy: 0.7657\n",
      "Epoch 101/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8071 - accuracy: 0.7657\n",
      "Epoch 102/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8014 - accuracy: 0.7679\n",
      "Epoch 103/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.7996 - accuracy: 0.7675\n",
      "Epoch 104/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7962 - accuracy: 0.7682\n",
      "Epoch 105/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7891 - accuracy: 0.7710\n",
      "Epoch 106/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7937 - accuracy: 0.7687\n",
      "Epoch 107/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7905 - accuracy: 0.7715\n",
      "Epoch 108/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7828 - accuracy: 0.7751\n",
      "Epoch 109/200\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.7787 - accuracy: 0.7740\n",
      "Epoch 110/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7789 - accuracy: 0.7731 0s - loss: 0.7787 - \n",
      "Epoch 111/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7787 - accuracy: 0.7735\n",
      "Epoch 112/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7799 - accuracy: 0.7743\n",
      "Epoch 113/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.7731 - accuracy: 0.7759\n",
      "Epoch 114/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7718 - accuracy: 0.7761\n",
      "Epoch 115/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7690 - accuracy: 0.7765\n",
      "Epoch 116/200\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.7683 - accuracy: 0.7767\n",
      "Epoch 117/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7654 - accuracy: 0.7798\n",
      "Epoch 118/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.7620 - accuracy: 0.7793\n",
      "Epoch 119/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.7603 - accuracy: 0.7789\n",
      "Epoch 120/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.7570 - accuracy: 0.7804\n",
      "Epoch 121/200\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.7578 - accuracy: 0.7803\n",
      "Epoch 122/200\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.7505 - accuracy: 0.7843\n",
      "Epoch 123/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7493 - accuracy: 0.7859\n",
      "Epoch 124/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7501 - accuracy: 0.7828\n",
      "Epoch 125/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7479 - accuracy: 0.7840\n",
      "Epoch 126/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7420 - accuracy: 0.7843\n",
      "Epoch 127/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7413 - accuracy: 0.7850\n",
      "Epoch 128/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7391 - accuracy: 0.7851\n",
      "Epoch 129/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7360 - accuracy: 0.7885\n",
      "Epoch 130/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7374 - accuracy: 0.7879\n",
      "Epoch 131/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7350 - accuracy: 0.7889\n",
      "Epoch 132/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7305 - accuracy: 0.7894\n",
      "Epoch 133/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7293 - accuracy: 0.7889\n",
      "Epoch 134/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7270 - accuracy: 0.7909\n",
      "Epoch 135/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7236 - accuracy: 0.7916\n",
      "Epoch 136/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7236 - accuracy: 0.7935\n",
      "Epoch 137/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7193 - accuracy: 0.7924\n",
      "Epoch 138/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7221 - accuracy: 0.7945\n",
      "Epoch 139/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7152 - accuracy: 0.7932\n",
      "Epoch 140/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7185 - accuracy: 0.7954\n",
      "Epoch 141/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7149 - accuracy: 0.7937\n",
      "Epoch 142/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7157 - accuracy: 0.7930\n",
      "Epoch 143/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7114 - accuracy: 0.7955 0s - loss: 0.7125 - accuracy\n",
      "Epoch 144/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7084 - accuracy: 0.7963\n",
      "Epoch 145/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7101 - accuracy: 0.7945\n",
      "Epoch 146/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7066 - accuracy: 0.7972\n",
      "Epoch 147/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7044 - accuracy: 0.7969\n",
      "Epoch 148/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.7035 - accuracy: 0.7980\n",
      "Epoch 149/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.7027 - accuracy: 0.7983\n",
      "Epoch 150/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6993 - accuracy: 0.7985\n",
      "Epoch 151/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6951 - accuracy: 0.7994\n",
      "Epoch 152/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6983 - accuracy: 0.8012\n",
      "Epoch 153/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6916 - accuracy: 0.8020\n",
      "Epoch 154/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6982 - accuracy: 0.7991\n",
      "Epoch 155/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6907 - accuracy: 0.8010\n",
      "Epoch 156/200\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.6893 - accuracy: 0.8012\n",
      "Epoch 157/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6898 - accuracy: 0.8003 1s -\n",
      "Epoch 158/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6911 - accuracy: 0.8000\n",
      "Epoch 159/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6852 - accuracy: 0.8038\n",
      "Epoch 160/200\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6872 - accuracy: 0.8024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6834 - accuracy: 0.8029\n",
      "Epoch 162/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6791 - accuracy: 0.8039\n",
      "Epoch 163/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6791 - accuracy: 0.8058\n",
      "Epoch 164/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6792 - accuracy: 0.8050\n",
      "Epoch 165/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6751 - accuracy: 0.8059\n",
      "Epoch 166/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6746 - accuracy: 0.8059\n",
      "Epoch 167/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6704 - accuracy: 0.8076\n",
      "Epoch 168/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6701 - accuracy: 0.8096\n",
      "Epoch 169/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6728 - accuracy: 0.8080\n",
      "Epoch 170/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6707 - accuracy: 0.8079\n",
      "Epoch 171/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6667 - accuracy: 0.8096\n",
      "Epoch 172/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6619 - accuracy: 0.8108\n",
      "Epoch 173/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6657 - accuracy: 0.8092\n",
      "Epoch 174/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6617 - accuracy: 0.8094\n",
      "Epoch 175/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6614 - accuracy: 0.8106\n",
      "Epoch 176/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6633 - accuracy: 0.8095\n",
      "Epoch 177/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6562 - accuracy: 0.8116\n",
      "Epoch 178/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6591 - accuracy: 0.8117\n",
      "Epoch 179/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6545 - accuracy: 0.8137\n",
      "Epoch 180/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6521 - accuracy: 0.8149\n",
      "Epoch 181/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6538 - accuracy: 0.8135\n",
      "Epoch 182/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6514 - accuracy: 0.8142\n",
      "Epoch 183/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6487 - accuracy: 0.8143\n",
      "Epoch 184/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6511 - accuracy: 0.8115\n",
      "Epoch 185/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6444 - accuracy: 0.8166\n",
      "Epoch 186/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6477 - accuracy: 0.8143\n",
      "Epoch 187/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6471 - accuracy: 0.8155\n",
      "Epoch 188/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6467 - accuracy: 0.8164\n",
      "Epoch 189/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6447 - accuracy: 0.8150\n",
      "Epoch 190/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6439 - accuracy: 0.8163\n",
      "Epoch 191/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6371 - accuracy: 0.8163\n",
      "Epoch 192/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6386 - accuracy: 0.8175\n",
      "Epoch 193/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6374 - accuracy: 0.8187\n",
      "Epoch 194/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6373 - accuracy: 0.8172\n",
      "Epoch 195/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6345 - accuracy: 0.8180\n",
      "Epoch 196/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6338 - accuracy: 0.8194\n",
      "Epoch 197/200\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6358 - accuracy: 0.8196\n",
      "Epoch 198/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6318 - accuracy: 0.8207\n",
      "Epoch 199/200\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6286 - accuracy: 0.8202\n",
      "Epoch 200/200\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6331 - accuracy: 0.8196\n",
      "Accuracy in validation dataset: {0} 0.8618666529655457\n",
      "563/563 [==============================] - 1s 3ms/step - loss: 0.6072 - accuracy: 0.8359\n",
      "Accuracy in test dataset : {0} 0.8359444737434387\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "Lambda = .0015\n",
    "x_val = x_val.reshape(60000, 1024)\n",
    "x_test = x_test.reshape(18000, 1024)\n",
    "score, finalmodel = train_and_test_loopFinalwithValidationData(200, lr, Lambda)\n",
    "print(\"Accuracy in validation dataset: {0}\", score[1])\n",
    "testscore = finalmodel.evaluate(x_test, y_test)\n",
    "print(\"Accuracy in test dataset : {0}\", testscore[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Print the classification accuracy metrics of final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_301\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1052 (Dense)           (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_539 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_719 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_487 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1053 (Dense)           (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_540 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_720 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_488 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1054 (Dense)           (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 332,810\n",
      "Trainable params: 331,786\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "finalmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 7 2 ... 7 9 2]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "x_test = xtest.reshape(18000, 1024)\n",
    "y_hat = finalmodel.predict_classes(x_test, batch_size=128, verbose=0)\n",
    "print(y_hat)\n",
    "pred = finalmodel.predict(x_test)\n",
    "print(pred.round())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_test=np.argmax(y_test, axis=1)\n",
    "y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1602   25   20   12   32    3   27   28   22   43]\n",
      " [  21 1552   41   19   81    7   16   57   18   16]\n",
      " [  13   25 1582   18   32   17    7   60   18   31]\n",
      " [  18   46   74 1244   30  145   23   44   53   42]\n",
      " [  21   37   44   11 1609   15   22   15    7   31]\n",
      " [  15   19   25   64   26 1451   69   17   43   39]\n",
      " [  39   19   25   12   64   58 1530   11   56   18]\n",
      " [  15   59   69   17   16   10   13 1572   11   26]\n",
      " [  28   38   40   26   40   29  110   12 1421   68]\n",
      " [  61   27   42   35   32   39   14   27   43 1484]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      1814\n",
      "           1       0.84      0.85      0.84      1828\n",
      "           2       0.81      0.88      0.84      1803\n",
      "           3       0.85      0.72      0.78      1719\n",
      "           4       0.82      0.89      0.85      1812\n",
      "           5       0.82      0.82      0.82      1768\n",
      "           6       0.84      0.84      0.84      1832\n",
      "           7       0.85      0.87      0.86      1808\n",
      "           8       0.84      0.78      0.81      1812\n",
      "           9       0.83      0.82      0.82      1804\n",
      "\n",
      "    accuracy                           0.84     18000\n",
      "   macro avg       0.84      0.84      0.84     18000\n",
      "weighted avg       0.84      0.84      0.84     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2\n",
    "Since this dataset is not giving accurate results using ANN lets try to see if we can increase the accuracy using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(18000, 1024)\n",
      "(60000, 1024)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(42000, 32, 32, 1)\n",
    "x_test = x_test.reshape(18000, 32, 32, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_and_test_Conv2DwithDropoutAndBatchNormalization(lr, Lambda, verb=True):\n",
    "\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "        \n",
    "    model = Sequential() \n",
    "    model.add(Conv2D(32, (2, 2), input_shape=(32, 32, 1))) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(32, (2, 2))) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten()) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(hidden_nodes))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10)) \n",
    "    model.add(Activation('softmax')) \n",
    " \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42/42 [==============================] - 78s 2s/step - loss: 1.7611 - accuracy: 0.4083\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 74s 2s/step - loss: 0.8975 - accuracy: 0.7237\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 74s 2s/step - loss: 0.6797 - accuracy: 0.7916\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 74s 2s/step - loss: 0.5903 - accuracy: 0.8188\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 74s 2s/step - loss: 0.5336 - accuracy: 0.8358\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 75s 2s/step - loss: 0.4930 - accuracy: 0.8474\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 74s 2s/step - loss: 0.4633 - accuracy: 0.8581\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 77s 2s/step - loss: 0.4351 - accuracy: 0.8657\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 74s 2s/step - loss: 0.4136 - accuracy: 0.8726\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 74s 2s/step - loss: 0.3911 - accuracy: 0.8806\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 74s 2s/step - loss: 0.3720 - accuracy: 0.8855\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 75s 2s/step - loss: 0.3517 - accuracy: 0.8924\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 74s 2s/step - loss: 0.3391 - accuracy: 0.8967\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 75s 2s/step - loss: 0.3246 - accuracy: 0.9014\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 74s 2s/step - loss: 0.3090 - accuracy: 0.9056\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 74s 2s/step - loss: 0.2997 - accuracy: 0.9067\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 75s 2s/step - loss: 0.2898 - accuracy: 0.9117\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 74s 2s/step - loss: 0.2824 - accuracy: 0.9126\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 74s 2s/step - loss: 0.2693 - accuracy: 0.9176\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 74s 2s/step - loss: 0.2561 - accuracy: 0.9221\n",
      "563/563 [==============================] - 6s 11ms/step - loss: 0.3344 - accuracy: 0.9021\n",
      "Accuracy in test set : {0} 0.902055561542511\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "Lambda = 0.1\n",
    "x_train = x_train.reshape(42000, 32, 32, 1)\n",
    "x_test = x_test.reshape(18000, 32, 32, 1)\n",
    "model = train_and_test_Conv2DwithDropoutAndBatchNormalization(lr, Lambda)\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=1000, verbose= 1)\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy in test set : {0}\", result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall observation\n",
    "\n",
    "1. Firstly we reshaped the dataset( train test and validation) so that imput file format is as per ANN requirement.\n",
    "2. Analyzed how the output is actually looking like, checked its grayimages as well.\n",
    "3. Prepared the model and tried for different value of learning rate and lambda\n",
    "4. Found the best values of hyperparameters for which we got best accuracy and validated the same model in validation set as well.\n",
    "5. So the best result using deep neural network was 86% accuracy in train and validation set and 84%  in test\n",
    "6. Tried to check the performance using Convolution layer and it is way better than deep neural network ( 91% accuracy noth in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
